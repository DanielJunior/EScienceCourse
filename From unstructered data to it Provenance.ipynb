{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# From unstructered data to it Provenance\n",
    "\n",
    "\n",
    "<div style=\"text-align: right\"> \n",
    "<h3>EScience - PPG IC/UFF 2017.1</h3>\n",
    "\n",
    "<h4>Daniel Junior, Kid Valeriano</h4>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Relembrando...\n",
    "O projeto tem como base o artigo <strong>Provenance as data mining: Combining file system metadata with content analysis</strong>.\n",
    "</hr>\n",
    "<li>A ideia é utilizar técnicas de Mineração de Dados para reconstruir a proveniência de dados não-estruturados.</li>\n",
    "<li>Os dados não-estruturados utilizados como dados de entrada para o projeto são arquivos textos contendo versões de um artigo até que o mesmo chegasse a sua edição final.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Arquitetura\n",
    "<div width=\"100%\" height=\"100%\">\n",
    "    <img src=\"images/arquitetura.png\" height=\"400\" width=\"800\" style=\"margin: 0 auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Projeto\n",
    "<ul>\n",
    "    <li>Linguagem Python</li>\n",
    "    <li>Biblioteca Sci-kit Learn</li>\n",
    "    <li>Os dados usados no experimento são do repositório <strong><a href=\"https://l.facebook.com/l.php?u=http%3A%2F%2F137.207.234.78%2Fsearch%2Fdetail%2F&h=ATMRd4R-lyI7h1CWdhxvn6UWFuIQ6Sk5lh5mt_Yl5P4cZtgMLg2Eab3JBX_fKeG0-K69PJBwnMqh8BrtHvD__C71t0gmJg-NTkGuLNtxIehOx2CwfwQx_44sEEALKLVSY6y_fg\">CiteSeerX</a></strong></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Projeto\n",
    "\n",
    "Os passos a serem seguidos são:\n",
    "\n",
    "<ol>\n",
    "    <li>Dado um diretório que contenha as revisões de arquivos, devo ser capaz de recuperar o conteúdo de cada arquivo.</li>\n",
    "    <li>Representar o conteúdo do arquivo de uma forma que seja possível aplicar algoritmos de Clustering.</li>\n",
    "    <li>Executar o algoritmo para criar os clusters.</li>\n",
    "    <li>Para cada arquivo em um arquivo, recuperar os metados relativos ao dados de modificação do arquivo.</li>\n",
    "    <li>Com os metadados em mãos, exportar para o PROV-Model, fazendo o armazenamento em um banco relacional (SQLite).</li>\n",
    "    <li>Ser capaz de receber um arquivo de entrada e retornar uma representação gŕafica da proveniência do mesmo.</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import os, time\n",
    "from stat import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Passo 1: Carregar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/d2/doc684.txt', 'data/d2/doc641.txt', 'data/d2/doc43.txt', 'data/d2/doc752.txt', 'data/d2/doc167.txt', 'data/d2/doc786.txt', 'data/d2/doc154.txt', 'data/d2/doc293.txt', 'data/d2/doc272.txt', 'data/d2/doc1142.txt']\n"
     ]
    }
   ],
   "source": [
    "PATH = \"data\"\n",
    "filenames = []\n",
    "docs = []\n",
    "for path, dirs, files in os.walk(PATH):\n",
    "    for filename in files:\n",
    "        fullpath = os.path.join(path, filename)\n",
    "        with open(fullpath, 'r') as f:\n",
    "            data = f.read()\n",
    "            filenames.append(fullpath)\n",
    "            docs.append(data)        \n",
    "\n",
    "print(filenames[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(docs, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Passo 2: Representação vetorial dos dados\n",
    "\n",
    "<div width=\"100%\" height=\"100%\">\n",
    "    <img src=\"images/tfidf.png\" style=\"margin: 0 auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Passo 2: Representação vetorial dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões da matriz:\n",
      "(928, 20202)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=200000,)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(train_data)\n",
    "print(\"Dimensões da matriz:\")\n",
    "print(tfidf_matrix.todense().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Before all we need to load data, as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rec.sport.baseball', 'talk.politics.mideast']\n"
     ]
    }
   ],
   "source": [
    "categories = [\n",
    "    'talk.politics.mideast',\n",
    "    'rec.sport.baseball',\n",
    "]\n",
    "\n",
    "train_data = fetch_20newsgroups(subset='train', categories=categories)\n",
    "test_data = fetch_20newsgroups(subset='test', categories=categories)\n",
    "labels = train_data.target_names\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file size: 3580\n",
      "file modified: Thu May 18 11:02:46 2017\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "PATH = \"data\"\n",
    "filenames = []\n",
    "docs = []\n",
    "#getting all path and files contents from PATH variable\n",
    "for path, dirs, files in os.walk(PATH):\n",
    "    for filename in files:\n",
    "        fullpath = os.path.join(path, filename)\n",
    "        with open(fullpath, 'r') as f:\n",
    "            data = f.read()\n",
    "            #appending filepath and content to array\n",
    "            filenames.append(fullpath)\n",
    "            docs.append(data)        \n",
    "\n",
    "#getting metadata from file\n",
    "st = os.stat(filenames[0])\n",
    "print(\"file size:\", st[ST_SIZE])\n",
    "print(\"file modified:\", time.asctime(time.localtime(st[ST_MTIME])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "After that, we will use TF-IDF to documents representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1d826ba6d418>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtfidf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mterms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(train_data.data)\n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "print(terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Then lets instance K-Means model and fit with TF-IDF matrix that we retrieve from last step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ..., 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "km = KMeans(n_clusters=2, init='k-means++', max_iter=100, n_init=1,\n",
    "                verbose=False)\n",
    "km.fit(tfidf_matrix.todense())\n",
    "print(km.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we are able to inspect clusters centers (showing only first 10 attributes) and make predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: edu year com baseball team game organization subject lines article\n",
      "Cluster 1: israel israeli edu jews turkish people armenian armenians com arab\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "for i in range(2):\n",
    "    print(\"Cluster %d:\" % i, end='')\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print()\n",
    "    \n",
    "km.predict(tfidf_vectorizer.transform(test_data.data).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#for idx, doc in enumerate(train_data.data):\n",
    " #   f = open('data/doc'+str(idx)+\".txt\", 'w')\n",
    "  #  f.write(doc)\n",
    "   # f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href=\"https://fonts.googleapis.com/css?family=Fira+Sans:300,300i,600,600i\" rel=\"stylesheet\">\n",
       "<link href=\"https://fonts.googleapis.com/css?family=Inconsolata\" rel=\"stylesheet\">\n",
       "<link href=\"https://fonts.googleapis.com/css?family=Titillium+Web:400,400i,700,700i\" rel=\"stylesheet\">\n",
       "<style>\n",
       ".text_cell_render {\n",
       "font-style: regular;\n",
       "font-family: 'Fira Sans', sans-serif;\n",
       "display: block;\n",
       "}\n",
       "/*font-weight: 200;*/\n",
       "/*text-align: left;\n",
       "line-height: 100%;\n",
       "display: block;\n",
       "}*/\n",
       ".text_cell_render h1 {\n",
       "/*font-size: 24pt;*/\n",
       "font-family: 'Titillium Web', sans-serif;\n",
       "font-weight: bold;\n",
       "margin-bottom: 0.1em;\n",
       "margin-top: 0.5em;\n",
       "color:#4a4a4a;\n",
       "}\n",
       "\n",
       ".reveal h1 {\n",
       "font-family: 'Titillium Web', sans-serif;\n",
       "/*font-size: 24pt;*/\n",
       "font-weight: bold;\n",
       "margin-bottom: 0.1em;\n",
       "margin-top: 0.5em;\n",
       "color:#4a4a4a;\n",
       "}\n",
       ".text_cell_render h2 {\n",
       "/*font-size: 21pt;*/\n",
       "    font-family: 'Titillium Web', sans-serif;\n",
       "margin-bottom: 0.1em;\n",
       "margin-top: 0.3em;\n",
       "color:#595959;\n",
       "}\n",
       ".text_cell_render h3 {\n",
       "    font-family: 'Titillium Web', sans-serif;\n",
       "/*font-size: 19pt;*/\n",
       "margin-bottom: 0.1em;\n",
       "margin-top: 0.3em;\n",
       "color:#595959;\n",
       "}\n",
       ".text_cell_render h4 {\n",
       "    font-family: 'Titillium Web', sans-serif;\n",
       "/*font-size: 17pt;*/\n",
       "margin-bottom: 0.1em;\n",
       "margin-top: 0.3em;\n",
       "color:#595959;\n",
       "}\n",
       ".text_cell_render h5 {\n",
       "    font-family: 'Titillium Web', sans-serif;\n",
       "/*font-size: 15pt;*/\n",
       "margin-bottom: 0.1em;\n",
       "margin-top: 0.3em;\n",
       "color:#595959;\n",
       "}\n",
       "div.text_cell_render{\n",
       "line-height: 120%;\n",
       "font-size: 100%;\n",
       "font-weight: 400;\n",
       "text-align: justify;\n",
       "margin-left:0em;\n",
       "margin-right:0em;\n",
       "}\n",
       ".reveal div.text_cell_render{\n",
       "line-height: 120%;\n",
       "font-size: 74%;\n",
       "font-weight: 400;\n",
       "text-align: justify;\n",
       "margin-left:0em;\n",
       "margin-right:0em;\n",
       "}\n",
       "\n",
       ".reveal h2 {\n",
       "font-family: 'Titillium Web', sans-serif;\n",
       "/*font-size: 24pt;*/\n",
       "font-weight: bold;\n",
       "margin-bottom: 0.1em;\n",
       "margin-top: 0.5em;\n",
       "color:#595959;\n",
       "}\n",
       ".reveal h3 {\n",
       "font-family: 'Titillium Web', sans-serif;\n",
       "/*font-size: 24pt;*/\n",
       "font-weight: bold;\n",
       "margin-bottom: 0.1em;\n",
       "margin-top: 0.5em;\n",
       "color:#595959;\n",
       "}\n",
       ".reveal h4 {\n",
       "font-family: 'Titillium Web', sans-serif;\n",
       "font-weight: bold;\n",
       "margin-bottom: 0.1em;\n",
       "margin-top: 0.5em;\n",
       "color:#595959;\n",
       "}\n",
       ".reveal .code_cell {\n",
       "    font-size: 83%;\n",
       "}\n",
       ".reveal code {\n",
       "font-family: 'Inconsolata', monospace;\n",
       "}\n",
       ".reveal pre {\n",
       "font-family: 'Inconsolata', monospace;\n",
       "}\n",
       "code {\n",
       "font-family: 'Inconsolata', monospace;\n",
       "}\n",
       "pre {\n",
       "font-family: 'Inconsolata', monospace;\n",
       "}\n",
       ".CodeMirror{\n",
       "font-family: \"Inconsolata\", monospace;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "from urllib.request import urlopen\n",
    "HTML(urlopen('https://raw.githubusercontent.com/lmarti/jupyter_custom/master/custom.include').read().decode('utf-8'))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
