<document id="10.1.1.1.1552"><clusterid>1099</clusterid><title src="user correction - Legacy Corrections">Towards a Generic Talking Head</title><abstract src="user correction - Legacy Corrections">We present here a framework for developing a generic talking head capable of reproducing the anatomy and the facial  deformations induced by speech movements with a set of a few parameters. We will show that the speaker-specific articulatory movements can be straightforward encoded into the normalized MPEG-4 Facial Animation Parameters and Facial Definition  Parameters.</abstract><year src="user correction - Legacy Corrections">2003</year><keywords><keyword id="1267">MPEG-4 Facial Animation Parameters and Facial Definition Parameters</keyword></keywords><authors><author id="null"><name src="user correction - Legacy Corrections">Brar Bailly Chabanas</name><order src="user correction - Legacy Corrections">1</order></author></authors><citations src="ParsCit 1.0"><citation id="29153"><clusterid>1100</clusterid><authors>P Badin,G Bailly,L Revéret,M Baciu,C Segebarth,C Savariaux</authors><title>Threedimentional linear articulatory modeling of tongue, lips and face based on MRI and video images</title><venue>Journal of Phonetics</venue><venType>JOURNAL</venType><year>2002</year><pages>533--553</pages><volume>30</volume><raw>Badin, P., Bailly, G., Revéret, L., Baciu, M., Segebarth, C., and Savariaux, C. (2002) Threedimentional linear articulatory modeling of tongue, lips and face based on MRI and video images. Journal of Phonetics, 30(3): p. 533-553.</raw><paperid>10.1.1.1.1552</paperid></citation><citation id="29154"><clusterid>1101</clusterid><authors>C Bregler,M Covell,M Slaney</authors><title>Video rewrite: visual speech synthesis from video</title><venue>in International Conference on Auditory-Visual Speech Processing. Rhodes</venue><venType>CONFERENCE</venType><year>1997</year><pages>153--156</pages><pubAddress>Greece</pubAddress><raw>Bregler, C., Covell, M., and Slaney, M. (1997) Video rewrite: visual speech synthesis from video. in International Conference on Auditory-Visual Speech Processing. Rhodes, Greece. p. 153-156.</raw><paperid>10.1.1.1.1552</paperid></citation><citation id="29155"><clusterid>1102</clusterid><authors>T F Cootes,G J Edwards,C J Taylor</authors><title>Active Appearance Models</title><venue>IEEE Transactions on Pattern Analysis and Machine Intelligence</venue><venType>JOURNAL</venType><year>2001</year><pages>681--685</pages><volume>23</volume><raw>Cootes, T.F., Edwards, G.J., and Taylor, C.J. (2001) Active Appearance Models. IEEE Transactions on Pattern Analysis and Machine Intelligence, 23(6): p. 681-685.</raw><paperid>10.1.1.1.1552</paperid></citation><citation id="29156"><clusterid>1103</clusterid><authors>B Couteau,Y Payan,S Lavallée</authors><title>The Mesh-Matching algorithm : an automatic 3D mesh generator for finite element structures</title><venue>Journal of Biomechanics</venue><venType>JOURNAL</venType><year>2000</year><pages>1005--1009</pages><volume>33</volume><raw>Couteau, B., Payan, Y., and Lavallée, S. (2000) The Mesh-Matching algorithm : an automatic 3D mesh generator for finite element structures. Journal of Biomechanics, 33(8): p. 1005-1009.</raw><paperid>10.1.1.1.1552</paperid></citation><citation id="29157"><clusterid>1104</clusterid><authors>P Eisert,B Girod</authors><title>Analyzing Facial Expressions for Virtual Conferencing</title><venue>IEEE Computer Graphics &amp; Applications: Special Issue: Computer Animation for Virtual Humans</venue><venType>JOURNAL</venType><year>1998</year><pages>70--78</pages><volume>18</volume><raw>Eisert, P. and Girod, B. (1998) Analyzing Facial Expressions for Virtual Conferencing. IEEE Computer Graphics &amp; Applications: Special Issue: Computer Animation for Virtual Humans, 18(5): p. 70-78.</raw><paperid>10.1.1.1.1552</paperid></citation><citation id="29158"><clusterid>1105</clusterid><authors>F Elisei,M Odisio,G Bailly,P Badin</authors><title>Creating and controlling video-realistic talking heads</title><venue>in Auditory-Visual Speech Processing Workshop. Scheelsminde</venue><venType>CONFERENCE</venType><year>2001</year><pages>90--97</pages><pubAddress>Denmark</pubAddress><raw>Elisei, F., Odisio, M., Bailly, G., and Badin, P. (2001) Creating and controlling video-realistic talking heads. in Auditory-Visual Speech Processing Workshop. Scheelsminde, Denmark. p. 90-97.</raw><paperid>10.1.1.1.1552</paperid></citation><citation id="29159"><clusterid>1106</clusterid><authors>T Ezzat,G Geiger,T Poggio</authors><title>Trainable videorealistic speech animation</title><venue>ACM Transactions on Graphics</venue><venType>JOURNAL</venType><year>2002</year><pages>388--398</pages><volume>21</volume><raw>Ezzat, T., Geiger, G., and Poggio, T. (2002) Trainable videorealistic speech animation. ACM Transactions on Graphics, 21(3): p. 388-398.</raw><paperid>10.1.1.1.1552</paperid></citation><citation id="29160"><clusterid>1107</clusterid><authors>B Guenter,C Grimm,D Wood,H Malvar,F Pighin</authors><title>Making faces</title><venue>in SIGGRAPH. Orlando - USA</venue><venType>CONFERENCE</venType><year>1998</year><pages>55--67</pages><raw>Guenter, B., Grimm, C., Wood, D., Malvar, H., and Pighin, F. (1998) Making faces. in SIGGRAPH. Orlando - USA. p. 55-67.</raw><paperid>10.1.1.1.1552</paperid></citation><citation id="29161"><clusterid>1108</clusterid><authors>R A Harshman,M E Lundy</authors><title>The PARAFAC model for three-way factor analysis and multidimensional scaling, in Research Methods for Multimode Data Analysis</title><year>1984</year><pages>122--215</pages><raw>Harshman, R.A. and Lundy, M.E. (1984) The PARAFAC model for three-way factor analysis and multidimensional scaling, in Research Methods for Multimode Data Analysis, H.G. Law, et al., Editors. Praeger: New-York. p. 122-215.</raw><paperid>10.1.1.1.1552</paperid></citation><citation id="29162"><clusterid>1109</clusterid><authors>M Hashi,J R Westbury,K Honda</authors><title>Vowel posture normalization</title><venue>Journal of the Acoustical Society of America</venue><venType>JOURNAL</venType><year>1998</year><pages>2426--2437</pages><volume>104</volume><raw>Hashi, M., Westbury, J.R., and Honda, K. (1998) Vowel posture normalization. Journal of the Acoustical Society of America, 104(4): p. 2426-2437.</raw><paperid>10.1.1.1.1552</paperid></citation><citation id="29163"><clusterid>1110</clusterid><authors>J Ostermann,M Beutnagel,A Fischer,Y Wang</authors><title>Integration of talking heads and text-tospeech synthesizers for visual TTS</title><venue>in International Conference on Speech and Language Processing. Sydney - Australia</venue><venType>CONFERENCE</venType><year>1998</year><pages>297--300</pages><raw>Ostermann, J., Beutnagel, M., Fischer, A., and Wang, Y. (1998) Integration of talking heads and text-tospeech synthesizers for visual TTS. in International Conference on Speech and Language Processing. Sydney - Australia. p. 297-300.</raw><paperid>10.1.1.1.1552</paperid></citation><citation id="29164"><clusterid>1111</clusterid><authors>I S Pandzic,R Forchheimer</authors><title>MPEG-4 facial animation. The standard, implementation and applications</title><year>2002</year><publisher>John Wiley &amp; Sons</publisher><pubAddress>Chichester, England</pubAddress><raw>Pandzic, I.S. and Forchheimer, R. (2002) MPEG-4 facial animation. The standard, implementation and applications. Chichester, England: John Wiley &amp; Sons.</raw><paperid>10.1.1.1.1552</paperid></citation><citation id="29165"><clusterid>1112</clusterid><authors>F Pighin,J Hecker,D Lischinski,R Szeliski,D H Salesin</authors><title>Synthesizing Realistic Facial Expressions from Photographs</title><venue>in Proceedings of Siggraph</venue><venType>CONFERENCE</venType><year>1998</year><pages>75--84</pages><pubAddress>Orlando, FL, USA</pubAddress><raw>Pighin, F., Hecker, J., Lischinski, D., Szeliski, R., and Salesin, D.H. (1998) Synthesizing Realistic Facial Expressions from Photographs. in Proceedings of Siggraph. Orlando, FL, USA. p. 75-84.</raw><paperid>10.1.1.1.1552</paperid></citation><citation id="29166"><clusterid>1113</clusterid><authors>F H Pighin,R Szeliski,D Salesin</authors><title>Resynthesizing facial animation through 3D modelbased tracking</title><venue>International Conference on Computer Vision</venue><venType>CONFERENCE</venType><year>1999</year><pages>143--150</pages><volume>1</volume><raw>Pighin, F.H., Szeliski, R., and Salesin, D. (1999) Resynthesizing facial animation through 3D modelbased tracking. International Conference on Computer Vision, 1: p. 143-150.</raw><paperid>10.1.1.1.1552</paperid></citation><citation id="29167"><clusterid>1114</clusterid><authors>L Revéret,G Bailly,P Badin</authors><title>MOTHER: a new generation of talking heads providing a flexible articulatory control for videorealistic speech animation</title><venue>in International Conference on Speech and Language Processing. Beijing</venue><venType>CONFERENCE</venType><year>2000</year><pages>755--758</pages><pubAddress>China</pubAddress><raw>Revéret, L., Bailly, G., and Badin, P. (2000) MOTHER: a new generation of talking heads providing a flexible articulatory control for videorealistic speech animation. in International Conference on Speech and Language Processing. Beijing - China. p. 755-758.</raw><paperid>10.1.1.1.1552</paperid></citation><citation id="29168"><clusterid>1115</clusterid><authors>S Runeson,G Frykholm</authors><title>Visual perception of lifted weight</title><venue>Journal of Experimental Psychology: Human Perception and Performance</venue><venType>JOURNAL</venType><year>1981</year><pages>733--740</pages><volume>7</volume><raw>Runeson, S. and Frykholm, G. (1981) Visual perception of lifted weight. Journal of Experimental Psychology: Human Perception and Performance, 7: p. 733-740.</raw><paperid>10.1.1.1.1552</paperid></citation><citation id="29169"><clusterid>1116</clusterid><authors>S Runeson,G Frykholm</authors><title>Kinematic specification of dynamics as an informational basis for person and action perception: Expectation, gender recognition, and deceptive intention</title><venue>Journal of Experimental Psychology: General</venue><venType>JOURNAL</venType><year>1983</year><pages>585--615</pages><volume>112</volume><raw>Runeson, S. and Frykholm, G. (1983) Kinematic specification of dynamics as an informational basis for person and action perception: Expectation, gender recognition, and deceptive intention. Journal of Experimental Psychology: General, 112: p. 585-615.</raw><paperid>10.1.1.1.1552</paperid></citation><citation id="29170"><clusterid>1117</clusterid><authors>R Szeliski,S Lavallée</authors><title>Matching 3-D Anatomical Surfaces with Non-Rigid Deformations using Octree-Splines</title><venue>International Journal of Computer Vision</venue><venType>JOURNAL</venType><year>1996</year><pages>171--186</pages><volume>18</volume><raw>Szeliski, R. and Lavallée, S. (1996) Matching 3-D Anatomical Surfaces with Non-Rigid Deformations using Octree-Splines. International Journal of Computer Vision, 18(2): p. 171-186.</raw><paperid>10.1.1.1.1552</paperid></citation><citation id="29171"><clusterid>1118</clusterid><authors>A M Tekalp,J Ostermann</authors><title>Face and 2-D Mesh animation</title><venue>in MPEG-4. Signal Processing: Image Communication</venue><venType>CONFERENCE</venType><year>2000</year><pages>387--421</pages><volume>15</volume><raw>Tekalp, A.M. and Ostermann, J. (2000) Face and 2-D Mesh animation in MPEG-4. Signal Processing: Image Communication, 15: p. 387-421.</raw><paperid>10.1.1.1.1552</paperid></citation><citation id="29172"><clusterid>1119</clusterid><authors>F Vignoli,C Braccini</authors><title>A text-speech synchronization technique with applications to talking heads</title><venue>in Auditory-Visual Speech Processing Conference</venue><venType>CONFERENCE</venType><year>1999</year><pages>128--132</pages><pubAddress>Santa Cruz, California, USA</pubAddress><raw>Vignoli, F. and Braccini, C. (1999) A text-speech synchronization technique with applications to talking heads. in Auditory-Visual Speech Processing Conference. Santa Cruz, California, USA. p. 128-132.</raw><paperid>10.1.1.1.1552</paperid></citation></citations><fileInfo><crawldate>Nov 19, 2007</crawldate><repID>rep1</repID><conversionTrace>PDFLib TET</conversionTrace><urls><url>http://www.icp.inpg.fr/ICP/publis/synthese/_mb/clonegen_mb_ISSP03.pdf</url></urls></fileInfo></document>