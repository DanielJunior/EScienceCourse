<document id="10.1.1.1.1559"><title src="SVM HeaderParse 0.1">Visualizing Multimedia Content on Paper Documents: Components of Key Frame Selection for Video Paper</title><abstract src="SVM HeaderParse 0.1">The components of a key frame selection algorithm for a paper-based multimedia browsing interface called Video Paper are described. Analysis of video image frames is combined with the results of processing the closed caption to select key frames that are printed on a paper document together with the closed caption. Bar codes positioned near the key frames allow a user to play the video from the corresponding times. This paper describes several component techniques that are being investigated for key frame selection in the Video Paper system, including face detection and text recognition. The Video Paper system implementation is also discussed.</abstract><keywords></keywords><authors><author id="4343"><name src="SVM HeaderParse 0.1">Jonathan J. Hull</name><address src="SVM HeaderParse 0.1">Menlo Park, CA</address><email src="SVM HeaderParse 0.1">hull @rii.ricoh.com</email><order>1</order></author><author id="4344"><name src="SVM HeaderParse 0.1">Berna Erol</name><address src="SVM HeaderParse 0.1">Menlo Park, CA</address><email src="SVM HeaderParse 0.1">berna_erol @rii.ricoh.com</email><order>2</order></author><author id="4345"><name src="SVM HeaderParse 0.1">Jamey Graham</name><address src="SVM HeaderParse 0.1">Menlo Park, CA</address><email src="SVM HeaderParse 0.1">jamey @rii.ricoh.com</email><order>3</order></author><author id="4346"><name src="SVM HeaderParse 0.1">Dar-shyang Lee</name><address src="SVM HeaderParse 0.1">Menlo Park, CA</address><email src="SVM HeaderParse 0.1">dsl@rii.ricoh.com</email><order>4</order></author></authors><citations src="ParsCit 1.0"><citation id="29277"><authors>T Arai,D Aust,S E Hudson</authors><title>PaperLink: A technique for hyperlinking from real paper to electronic content</title><venue>Conference on Human Factors in Computing Systems (CHI</venue><venType>CONFERENCE</venType><year>1997</year><pages>327--334</pages><raw>Arai, T., Aust, D., and Hudson, S. E., “PaperLink: A technique for hyperlinking from real paper to electronic content,” Conference on Human Factors in Computing Systems (CHI 1997), 327-334.</raw><contexts><context>video browsing and retrieval was described. In contrast to the prior art, which relies on manual effort by the user to create a multimedia document which links a paper representation to digital data ([1, 6, 11]), Video Paper is a fully automatic solution that creates a paper document which allows users to quickly access information in a long recording by reading the transcript or browsing key frames. Recent</context></contexts></citation><citation id="29278"><authors>J Boreczky,A Girgensohn,G Golovchinsky,S Uchihashi</authors><title>An Interactive Comic Book Presentation for Exploring Video</title><venue>Conference on Proceedings of the Seventh International Conference on Document Analysis and Recognition (ICDAR 2003) 0-7695-1960-1/03 $17.00 © 2003 IEEE Human factors in Computing Systems (CHI 2000</venue><venType>CONFERENCE</venType><year>2000</year><pages>185--192</pages><raw>Boreczky, J., A. Girgensohn, G. Golovchinsky, and S. Uchihashi, “An Interactive Comic Book Presentation for Exploring Video,” Conference on Proceedings of the Seventh International Conference on Document Analysis and Recognition (ICDAR 2003) 0-7695-1960-1/03 $17.00 © 2003 IEEE Human factors in Computing Systems (CHI 2000), pp. 185-192, 2000.</raw><contexts><context>wind, etc., all but the most motivated users will easily give up and save this task for another day. Browsing is an alternative to active search that is used by many online video retrieval interfaces [2, 3, 9, 10]. However, these methods are still limited by what can be displayed on a PC monitor. On the other hand, it’s well known that people can read three times faster than they can listen which suggests that</context></contexts></citation><citation id="29279"><authors>P Chiu,A Kapuskar,S Reitmeier,L Wilcox</authors><title>Notelook: Taking Notes</title><venue>in Meetings with Digital Video and Ink,” ACM Multimedia ’99</venue><venType>CONFERENCE</venType><year>1999</year><pubAddress>Orlando, FL</pubAddress><raw>P. Chiu, A. Kapuskar, S. Reitmeier, and L. Wilcox, “Notelook: Taking Notes in Meetings with Digital Video and Ink,” ACM Multimedia ’99, Oct. 1999, Orlando, FL.</raw><contexts><context>wind, etc., all but the most motivated users will easily give up and save this task for another day. Browsing is an alternative to active search that is used by many online video retrieval interfaces [2, 3, 9, 10]. However, these methods are still limited by what can be displayed on a PC monitor. On the other hand, it’s well known that people can read three times faster than they can listen which suggests that</context></contexts></citation><citation id="29280"><authors>J Graham</authors><title>The Reader´s Helper: A Personalized Document Reading Environment</title><venue>Proc. of the CHI 99 conference on Human factors in computing systems: the CHI is the limit</venue><venType>CONFERENCE</venType><year>1999</year><pages>481--488</pages><raw>J. Graham, “The Reader´s Helper: A Personalized Document Reading Environment,” Proc. of the CHI 99 conference on Human factors in computing systems: the CHI is the limit, May 1999, 481-488.</raw><contexts><context>es in the closed caption transcript and optionally annotates them in the paperbased interface. Topics and keywords are stored in a user’s profile (this is an application of the Reader’s Helper profile[4] that was originally developed for improving the readability of html documents). A profilesthus provides a convenient means for representing information that a user would like the system to find in a </context></contexts></citation><citation id="29281"><authors>J Graham,J J Hull</authors><title>Video Paper: A Paperbased interface for skimming and watching video</title><venue>International Conference on Consumer Electronics (ICCE</venue><venType>CONFERENCE</venType><year>2002</year><pages>214--215</pages><pubAddress>Los Angeles, CA</pubAddress><raw>J. Graham and J. J. Hull, “Video Paper: A Paperbased interface for skimming and watching video,” International Conference on Consumer Electronics (ICCE), Los Angeles, CA, June 2002, 214-215.</raw><contexts><context> can listen which suggests that a paper-based interface could provide a more efficient search mechanism than an online media viewer. Video Paper is a paper-based interface for accessing digital video [5]. The closed caption transcript that’s often provided with a television program is formatted and printed together with key frames selected from the video. Bar codes are also included so that with a si</context></contexts></citation><citation id="29282"><authors>D L Hecht</authors><title>Printed Embedded Data Graphical User Interfaces</title><venue>IEEE Computer</venue><venType>JOURNAL</venType><year>2001</year><pages>4--7</pages><raw>D. L. Hecht, “Printed Embedded Data Graphical User Interfaces,” IEEE Computer, March 2001, 47-</raw><contexts><context>video browsing and retrieval was described. In contrast to the prior art, which relies on manual effort by the user to create a multimedia document which links a paper representation to digital data ([1, 6, 11]), Video Paper is a fully automatic solution that creates a paper document which allows users to quickly access information in a long recording by reading the transcript or browsing key frames. Recent</context></contexts></citation><citation id="29283"><authors>S Klemmer,J Graham,G Wolff,J Landay</authors><title>Books with voices: Paper transcripts as a physical interface to oral histories</title><venue>ACM Conference on Human Factors in Computing Systems (CHI-2003), Fort Lauderdale</venue><venType>CONFERENCE</venType><pages>5--10</pages><pubAddress>Florida</pubAddress><raw>S. Klemmer, J. Graham, G. Wolff, and J. Landay, “Books with voices: Paper transcripts as a physical interface to oral histories,” ACM Conference on Human Factors in Computing Systems (CHI-2003), Fort Lauderdale, Florida, April 5-10, 2003.</raw><contexts><context>in our lab. The remote control mentioned in the Introduction is connected to our WiFi LAN and allows users to replay Video Paper documents on demand. Video Paper is also being used for oral histories [7]. These are interviews of the observers or participants in historical events. Typically, the interviews are recorded and transcribed. Because of the difficulty in accessing the audio, subsequent analy</context></contexts></citation><citation id="29284"><authors>H Li,D Doermann,O Kia</authors><title>Automatic Text Detection and Tracking</title><venue>in Digital Video,” IEEE Transactions on Image Processing - Special Issue on Image and Video Processing for Digital Libraries</venue><venType>CONFERENCE</venType><year>2000</year><pages>147--156</pages><volume>9</volume><raw>H. Li, D. Doermann, and O. Kia. “Automatic Text Detection and Tracking in Digital Video,” IEEE Transactions on Image Processing - Special Issue on Image and Video Processing for Digital Libraries, 9(1), 147-156, 2000 .</raw><contexts><context> accuracy can be significant, especially for video data, since there is usually little text displayed on the TV screen at any one time. This is taken into account by a text-tracking algorithm such as [8]. Also, the presence of the same text in the closed caption and a video frame is evidence that the corresponding frame should be placed on the paper document. An example of the utility this could prov</context></contexts></citation><citation id="29285"><authors>B Shahraray,D C Gibbon</authors><title>Automated Authoring of Hypermedia Documents of Video Programs</title><venue>ACM Multimedia 95</venue><venType>JOURNAL</venType><pages>5--9</pages><pubAddress>San Francisco, CA</pubAddress><raw>B. Shahraray and D. C. Gibbon, “Automated Authoring of Hypermedia Documents of Video Programs”, ACM Multimedia 95, November 5-9, 1995, San Francisco, CA.</raw><contexts><context>wind, etc., all but the most motivated users will easily give up and save this task for another day. Browsing is an alternative to active search that is used by many online video retrieval interfaces [2, 3, 9, 10]. However, these methods are still limited by what can be displayed on a PC monitor. On the other hand, it’s well known that people can read three times faster than they can listen which suggests that</context></contexts></citation><citation id="29286"><authors>M A Smith,T Kanade</authors><title>Video skimming and characterization through the combination of image and language understanding</title><venue>in Proc. IEEE International Workshop on Content Based Access of Image and Video Database</venue><venType>CONFERENCE</venType><year>1998</year><pages>61--70</pages><raw>M.A. Smith and T. Kanade, &amp;quot;Video skimming and characterization through the combination of image and language understanding, &amp;quot; in Proc. IEEE International Workshop on Content Based Access of Image and Video Database, 1998, pp. 61--70.</raw><contexts><context>wind, etc., all but the most motivated users will easily give up and save this task for another day. Browsing is an alternative to active search that is used by many online video retrieval interfaces [2, 3, 9, 10]. However, these methods are still limited by what can be displayed on a PC monitor. On the other hand, it’s well known that people can read three times faster than they can listen which suggests that</context></contexts></citation><citation id="29287"><authors>L Stifelman,B Arons,C Schmandt</authors><title>The Audio Notebook: Paper and Pen Interaction with Structured Speech</title><venue>ACM CHI Conference</venue><venType>JOURNAL</venType><pages>182--189</pages><pubAddress>Seattle, WA</pubAddress><volume>5</volume><raw>L. Stifelman, B. Arons, and C. Schmandt, “The Audio Notebook: Paper and Pen Interaction with Structured Speech,” ACM CHI Conference, Seattle, WA, March 31 – April 5, 2001, 182-189.</raw><contexts><context>video browsing and retrieval was described. In contrast to the prior art, which relies on manual effort by the user to create a multimedia document which links a paper representation to digital data ([1, 6, 11]), Video Paper is a fully automatic solution that creates a paper document which allows users to quickly access information in a long recording by reading the transcript or browsing key frames. Recent</context></contexts></citation><citation id="29288"><authors>A Waibel,M Bett,F Metze,K Ries,T Schaaf,T Schultz,H Soltau,H Yu,K Zechner</authors><title>Advances in automatic meeting record creation and access</title><venue>Proceedings of the International Conference on Acoustics, Speech, and Signal Processing</venue><venType>CONFERENCE</venType><pages>200--1</pages><volume>597600</volume><raw>A. Waibel, M. Bett, F. Metze, K. Ries, T. Schaaf, T. Schultz, H. Soltau, H. Yu, and K. Zechner, &amp;quot;Advances in automatic meeting record creation and access&amp;quot;, Proceedings of the International Conference on Acoustics, Speech, and Signal Processing, 597600, 2001.</raw><contexts><context>the closed caption transcript to suggest key frames that could be useful to someone who browses a Video Paper document. The face detection algorithm first finds skin pixels in the normalized RG-space [12]. Small holes in skincolored regions are removed by a morphological closing Proceedings of the Seventh International Conference on Document Analysis and Recognition (ICDAR 2003) 0-7695-1960-1/03 $17.0</context></contexts></citation></citations><fileInfo><url>http://www.csc.liv.ac.uk/%7Eprima/ICDAR2003/Papers/0071_631_hull_j.pdf</url><repID>rep1</repID><conversionTrace>PDFLib TET</conversionTrace><checkSums><checkSum><fileType>pdf</fileType><sha1>9078eb471cd00f9e0e5856a863bdb55b41aa5c20</sha1></checkSum></checkSums></fileInfo></document>