<document id="10.1.1.1.1574"><title src="SVM HeaderParse 0.1">3.1.1 Using histograms............................. 6</title><abstract src="SVM HeaderParse 0.1">Submitted as part fullfilment for</abstract><keywords></keywords><authors><author id="4378"><name src="SVM HeaderParse 0.1">François Pitié</name><address src="SVM HeaderParse 0.1">; Diplôme d’ingénieur for ENST Bretagne/Eurecom, FRANCE</address><email src="SVM HeaderParse 0.1">anil.kokaram@tcd.ie</email><order>1</order></author></authors><citations src="ParsCit 1.0"><citation id="29585"><authors>P Bouthémy,M Gelgon,F Ganansia</authors><title>A unified approach to shot change detection and camera motion characterization</title><venue>IEEE Transactions on Circuits and Systems for Video Technology</venue><venType>JOURNAL</venType><year>1999</year><volume>9</volume><raw>P. Bouthémy, M. Gelgon, and F. Ganansia. A unified approach to shot change detection and camera motion characterization. IEEE Transactions on Circuits and Systems for Video Technology, 9:1030–1044, 1999.</raw><contexts><context>he frames (translation, zoom and rotation). The affine model is needed since some frames are rotated. The estimation itself is performed 28sthrough M-estimators. Part of the algorithm is described in [5, 1]. We used then the restoration process described in chapter 5 to compensate the frames. The estimation process takes around 3 seconds per frame on a PC and about 10 hours for the whole movie. The comp</context></contexts></citation><citation id="29586"><authors>P Charbonnier,L Blanc-Féraud,G Aubert,M Barlaud</authors><title>Two deterministic half quadratic regularization algorithms for computed imaging</title><venue>In International Conference on Image Processing</venue><venType>CONFERENCE</venType><year>1994</year><pages>168--172</pages><pubAddress>Austin, USA</pubAddress><raw>P. Charbonnier, L. Blanc-Féraud, G. Aubert, and M. Barlaud. Two deterministic half quadratic regularization algorithms for computed imaging. In International Conference on Image Processing, pages 168–172, Austin, USA, 1994.</raw><contexts><context>if!) Φ is squared, ΦΦ T = id. This introduces some simplifications in the IRLS algorithm and thus reduces the computational complexity. Optimizations can be even better if we use the LEGEND algorithm [2] instead of the classical IRLS. This algorithm was also described in [9] using iterative modified residuals [3]. With this algorithm we need only one matrix inversion: (ΦΦ T ) −1 = id. But unfortunate</context></contexts></citation><citation id="29587"><authors>R Dahyot</authors><title>Appearance based road scene video analysis for the management of the road network</title><venType>TECHREPORT</venType><year>2001</year><pubAddress>France</pubAddress><tech>PhD thesis</tech><raw>R. Dahyot. Appearance based road scene video analysis for the management of the road network. PhD thesis, University of Strasbourg I, France, November 2001.</raw><contexts><context> some weight mask. E(ε) = � ρ(ε(x)) (4.4) � â, ˆ � b x = � ρ(In+1 − diag (In) · Φa + Φb) (4.5) x = arg min (a,b) a1 . ap ⎞ ⎟ ⎠ � ρ(In+1 − diag (In) · Φa + Φb) (4.6) x Several functions ρ can be used ([9, 7, 3]). We arbitrarily decided to choose the Cauchy’s one: ρ(ε(x)) = 1 2 log � 1 + ε(x) 2� 4.2.3 Iterative Reweighted Least Square (IRLS) The minimization of the energy can be done through the classical IR</context><context>omputational complexity. Optimizations can be even better if we use the LEGEND algorithm [2] instead of the classical IRLS. This algorithm was also described in [9] using iterative modified residuals [3]. With this algorithm we need only one matrix inversion: (ΦΦ T ) −1 = id. But unfortunately, the computation complexity was not our first priority, we had not enough time to fully compare both algorit</context><context>e parameter a is usually close to 1. We decided accordingly to base the constraint on this fact. With a bayesian approach, the M-estimation is actually equivalent to the Maximum Likelihood estimation [3]. (â, ˆ b) = arg max P (In, In+1|a, b) (a,b) � � � = arg max exp − (a,b) x 1 2 ρ � �� ε(x) σρ � � � � � ε(x) = arg min ρ (a,b) � If we look at the Maximum A Posteriori Estimation: x (â, ˆ b) = arg max</context></contexts></citation><citation id="29588"><authors>E Decencière</authors><title>Restauration automatique de films anciens</title><venType>TECHREPORT</venType><year>1997</year><tech>PhD thesis</tech><raw>E. Decencière. Restauration automatique de films anciens. PhD thesis, Ecole Nationale Supérieure des Mines de Paris, December 1997.</raw><contexts><context> movie is played in real time. For more examples see http://www.mee.tcd.ie/ ∼ sigmedia/ifc/flicker/shots/ Figure 2.1: Flicker effect on a sequence of the Irish movie Rory O’More (1911). Previous work [4], [15] consider that flicker can be modeled as a spatially varying gain and 4soffset function. In+1(x, y) = a(x, y) · In(x, y) + b(x, y) (2.1) This equation establishes the relationship between the in</context><context>e improved in section 4.7.1. Sequences affected by flicker show low frequency spatial degradation. Therefore the functions of gain a(x, y) and offset b(x, y) should be low frequency. Previous work by [4], [15] employs a 2-dimensional polynomial basis. For example: a(x, y) = a0,0 + a1,0 x + ... + ai,j x i y j b(x, y) = b0,0 + b1,0 x + ... + bi,j x i y j The figure 2.2 shows an example of flicker follo</context><context>first method to measure the flicker strength is based on the fact that the strength of the flicker is directly linked to the intensity mean of the image. This method has been often used in literature [4, 15, 12, 11] to check the quality of the results of a flicker-removal process in a sequence since the mean intensity of a sequence without flicker is generally steady. If we note: f(u) = u + δ(u) δ(u) represents </context><context>mator. 4.1 Overview of the existing methods This section presents a brief overview of the estimation methods that have been proposed in the literature. 4.1.1 Parameters estimation Decencière’s method [4]. The method proposed by Decencière in his thesis is based on histogram matching. He uses a zeroth order model for the flicker: with a and b spatially constants for each frame. In+1 = a · In + b Assum</context><context>he effects that we want to preserve. 5.2.2 Formulation of the problem. Our formulation of the problem is partly based on the restoration process that Decencière proposed to remove translational shake [4]. But with our modeling it is possible to deal with much more general cases and not only with transitional shake but also with the two steps of the flicker restoration or with our affine shake removal</context></contexts></citation><citation id="29589"><authors>P Delacourt,A Kokaram,R Dahyot</authors><title>Comparison of global motion estimators</title><venue>In proceedings of Irish Signals and Systems Conference</venue><venType>CONFERENCE</venType><year>2002</year><pubAddress>Cork, Ireland</pubAddress><raw>P. Delacourt, A. Kokaram, and R. Dahyot. Comparison of global motion estimators. In proceedings of Irish Signals and Systems Conference, Cork, Ireland, June 2002.</raw><contexts><context>he frames (translation, zoom and rotation). The affine model is needed since some frames are rotated. The estimation itself is performed 28sthrough M-estimators. Part of the algorithm is described in [5, 1]. We used then the restoration process described in chapter 5 to compensate the frames. The estimation process takes around 3 seconds per frame on a PC and about 10 hours for the whole movie. The comp</context></contexts></citation><citation id="29590"><authors>F Galton</authors><title>Regression towards mediocrity in hereditary stature</title><venue>Journal of the Anthropological Institute</venue><venType>JOURNAL</venType><pages>246--263</pages><raw>F. Galton. Regression towards mediocrity in hereditary stature. Journal of the Anthropological Institute, pages 246–263, 1886.</raw><contexts><context>ems (at zeroth order in x and y) will give symmetric solutions: ⎧ ⎨ε1(x) = In(x) − a1 · In+1(x) − b1 ⎩ε2(x) = In+1(x) − a2 · In(x) − b2 (4.10) Unfortunately this expectation is not correct. As Galton [14, 6] showed when establishing the principle of regression, if the correlation between the random variables In and In+1 is not 1, then we cannot have: ⎧ ⎨ ⎩ â2 = 1 â1 ˆb2 = − ˆb1 â1 (4.11) For more informa</context></contexts></citation><citation id="29591"><authors>S Geman,G Reynolds</authors><title>Constrained restoration and the recovery of discontinuities</title><venue>IEEE Transactions on Pattern Analysis Machine Intelligence</venue><venType>JOURNAL</venType><year>1992</year><volume>14</volume><raw>S. Geman and G. Reynolds. Constrained restoration and the recovery of discontinuities. IEEE Transactions on Pattern Analysis Machine Intelligence, 14(3):367–383, March 1992.</raw><contexts><context> some weight mask. E(ε) = � ρ(ε(x)) (4.4) � â, ˆ � b x = � ρ(In+1 − diag (In) · Φa + Φb) (4.5) x = arg min (a,b) a1 . ap ⎞ ⎟ ⎠ � ρ(In+1 − diag (In) · Φa + Φb) (4.6) x Several functions ρ can be used ([9, 7, 3]). We arbitrarily decided to choose the Cauchy’s one: ρ(ε(x)) = 1 2 log � 1 + ε(x) 2� 4.2.3 Iterative Reweighted Least Square (IRLS) The minimization of the energy can be done through the classical IR</context></contexts></citation><citation id="29592"><authors>R Gonzalez,P Wintz</authors><venue>Digital Image Processing. 2nd edition</venue><venType>CONFERENCE</venType><year>1987</year><raw>R. Gonzalez and P. Wintz. Digital Image Processing. 2nd edition, 1987.</raw><contexts><context>on is applied globally to the image. For each gray level u in In we can associate the gray level v = f(u) in In+1. v = f(u) = a · u + b Come the p.d.f. of the image h(u). We have the general equation [8]: hn(u) du = hn+1(v) dv (3.1) hn(u) du = hn+1(f(u)) df(u) Considering flicker case of zero order gain and offset: hn(u) = hn+1(f(u)) f ′ (u) (3.2) hn(u) = a · hn+1(a · u + b) (3.3) The figure 3.1 show</context><context>me. The idea is to estimate the function f such that: f (In) = In+1 Finding f can be performed by using standard method of histogram matching. This method uses the cumulated histograms of both images [11, 8] (Cn and Cn+1). � u0 u=0 hn(u) du = hn+1(v) dv hn(u) du = � v0 0 hn+1(v) dv Cn(u) = Cn+1(f(u)) Since the cumulated histograms functions are monotonous it is possible to compute their inverse. Then we </context></contexts></citation><citation id="29593"><authors>P J Huber</authors><title>Robust Statistics</title><year>1981</year><publisher>John Wiley and Sons</publisher><pubAddress>New York</pubAddress><raw>P.J. Huber. Robust Statistics. John Wiley and Sons, New York, 1981.</raw><contexts><context> ⎞ ⎛ ⎟ ⎜ ⎠ ⎝ The problem is now to find the parameters which minimize some robust cost function E(ε) of the error made on the model. The minimization of this energy was done here through M-estimation [9]. The M-estimation has the advantages of being a robust estimation method, relatively easy to implement and fast. With Least Mean Square formulation, the energy minimized is quadratic in the error. He</context><context> some weight mask. E(ε) = � ρ(ε(x)) (4.4) � â, ˆ � b x = � ρ(In+1 − diag (In) · Φa + Φb) (4.5) x = arg min (a,b) a1 . ap ⎞ ⎟ ⎠ � ρ(In+1 − diag (In) · Φa + Φb) (4.6) x Several functions ρ can be used ([9, 7, 3]). We arbitrarily decided to choose the Cauchy’s one: ρ(ε(x)) = 1 2 log � 1 + ε(x) 2� 4.2.3 Iterative Reweighted Least Square (IRLS) The minimization of the energy can be done through the classical IR</context><context>e IRLS algorithm and thus reduces the computational complexity. Optimizations can be even better if we use the LEGEND algorithm [2] instead of the classical IRLS. This algorithm was also described in [9] using iterative modified residuals [3]. With this algorithm we need only one matrix inversion: (ΦΦ T ) −1 = id. But unfortunately, the computation complexity was not our first priority, we had not en</context></contexts></citation><citation id="29594"><authors>A Kokaram</authors><title>Motion Picture Restoration: Digital Algorithms for Artefact Suppression in Degraded Motion Picture Film and Video</title><year>1998</year><publisher>Springer Verlag</publisher><raw>A. Kokaram. Motion Picture Restoration: Digital Algorithms for Artefact Suppression in Degraded Motion Picture Film and Video. Springer Verlag, 1998.</raw><contexts><context>uter and about 10 hours on 10 PC’s for the whole movie. But programs are here running on matlab. More clever programming should definitely reduces the computation time. Blotch removal/Noise reduction [10]. Blotches are one of the most common degradations appearing in archived footage. Large pieces of dirt, holes in the film emulsion, and dust on the film are all perceived as blotches. Because blotches</context><context>ry difficult in blotchy film! Our deblotching process therefore treats noise and blotches simultaneously, using a Markov Chain Monte Carlo (MCMC) technique. This is the JOMBADI algorithm described in [10]. The restoration process takes around 40 seconds per frame on a computer and about 10 hours on 10 PC’s for the whole movie. But some frames where too badly damaged and needed more attention. Line Rem</context></contexts></citation><citation id="29595"><authors>V Naranjo,A Albiol</authors><title>Flicker reduction in old films</title><venue>In Proc. of the 2000 International Conference on Image Processing (ICIP-2000</venue><venType>CONFERENCE</venType><year>2000</year><raw>V. Naranjo and A. Albiol. Flicker reduction in old films. In Proc. of the 2000 International Conference on Image Processing (ICIP-2000), September 2000.</raw><contexts><context>first method to measure the flicker strength is based on the fact that the strength of the flicker is directly linked to the intensity mean of the image. This method has been often used in literature [4, 15, 12, 11] to check the quality of the results of a flicker-removal process in a sequence since the mean intensity of a sequence without flicker is generally steady. If we note: f(u) = u + δ(u) δ(u) represents </context><context>nell&amp;Wilcox had for instance based their flicker removal on this algorithm. Roosmalen had also proposed some other improvements for the flicker removal (cf. sections 4.1.2 and 5.1.2) Naranjo’s method [11] can be used at zeroth order in x and y. His method is based on histogram matching. The histogram of the degraded frame is transformed into a target histogram which corresponds to the expected histogr</context><context>me. The idea is to estimate the function f such that: f (In) = In+1 Finding f can be performed by using standard method of histogram matching. This method uses the cumulated histograms of both images [11, 8] (Cn and Cn+1). � u0 u=0 hn(u) du = hn+1(v) dv hn(u) du = � v0 0 hn+1(v) dv Cn(u) = Cn+1(f(u)) Since the cumulated histograms functions are monotonous it is possible to compute their inverse. Then we </context><context>ng and certainly some improvement to increase the robustness. We implemented a robust estimator of flicker severity based on Ohuchi’s method [12]. However, the classical restoration procedures failed [12, 11] to restore correctly the heavily degraded movie Rory O’More. Therefore, we improved several important aspects of the classical estimators, such as removing the bias due to regression and changing the</context></contexts></citation><citation id="29596"><authors>T Ohuchi,T Seto,T Komatsu,T Saito</authors><title>A robust method of image flicker correction for heavily-corrupted old film sequences</title><venue>In Proc. of the 2000 International Conference on Image Processing (ICIP-2000</venue><venType>CONFERENCE</venType><year>2000</year><raw>T. Ohuchi, T. Seto, T. Komatsu, and T. Saito. A robust method of image flicker correction for heavily-corrupted old film sequences. In Proc. of the 2000 International Conference on Image Processing (ICIP-2000), September 2000.</raw><contexts><context>. . . . 10 4.1.1 Parameters estimation . . . . . . . . . . . . . . . . . . . . . . . . . . 10 4.1.2 Flicker Localization . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 4.1.3 Ohuchi’s method [12] . . . . . . . . . . . . . . . . . . . . . . . . . . 12 4.2 Robust Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 4.2.1 Matrix formulation . . . . . . . . . . . . . . </context><context>first method to measure the flicker strength is based on the fact that the strength of the flicker is directly linked to the intensity mean of the image. This method has been often used in literature [4, 15, 12, 11] to check the quality of the results of a flicker-removal process in a sequence since the mean intensity of a sequence without flicker is generally steady. If we note: f(u) = u + δ(u) δ(u) represents </context><context> var[In+1(x, y)] a = ; b = E[In+1(x, y)] − a · E[In(x, y)] var[In(x, y)] This method corresponds to the least mean square solution of the problem. This method is a popular method. It has been used by [17, 12] and the company Snell&amp;Wilcox had for instance based their flicker removal on this algorithm. Roosmalen had also proposed some other improvements for the flicker removal (cf. sections 4.1.2 and 5.1.2)</context><context>neighbor blocks parameters. Once parameters a and b have been found for all blocks, to avoid block effect, parameters are interpolated in each pixel by a bilinear interpolation. 4.1.3 Ohuchi’s method [12] Local motion and blotches cause problems to the estimator proposed by Roosmalen. Robust estimators are a particular class of estimators suitable to solve these kind problems. From the work of Roosmal</context><context>licker diagnosis module. This part needs some further testing and certainly some improvement to increase the robustness. We implemented a robust estimator of flicker severity based on Ohuchi’s method [12]. However, the classical restoration procedures failed [12, 11] to restore correctly the heavily degraded movie Rory O’More. Therefore, we improved several important aspects of the classical estimator</context></contexts></citation><citation id="29597"><authors>W H Press,S A Teukolsky,W T Vetterling,B P Flannery</authors><venue>Numerical Recipes in C - The Art of Scientific Computing</venue><venType>CONFERENCE</venType><year>1995</year><publisher>Cambridge University Press</publisher><raw>W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery. Numerical Recipes in C - The Art of Scientific Computing. Cambridge University Press, 1995.</raw></citation><citation id="29598"><authors>S M Stigler</authors><title>The History of Statistics</title><year>1986</year><publisher>Belknap Press of Harvard Press</publisher><pubAddress>Cambridge</pubAddress><raw>S.M Stigler. The History of Statistics. Cambridge: Belknap Press of Harvard Press, 1986.</raw><contexts><context>ems (at zeroth order in x and y) will give symmetric solutions: ⎧ ⎨ε1(x) = In(x) − a1 · In+1(x) − b1 ⎩ε2(x) = In+1(x) − a2 · In(x) − b2 (4.10) Unfortunately this expectation is not correct. As Galton [14, 6] showed when establishing the principle of regression, if the correlation between the random variables In and In+1 is not 1, then we cannot have: ⎧ ⎨ ⎩ â2 = 1 â1 ˆb2 = − ˆb1 â1 (4.11) For more informa</context></contexts></citation><citation id="29599"><authors>P M B van Roosmalen</authors><title>Restoration of archived film and video</title><venType>TECHREPORT</venType><year>1999</year><tech>PhD thesis</tech><raw>P.M.B. van Roosmalen. Restoration of archived film and video. PhD thesis, Delft University of Technology, October 1999.</raw><contexts><context>e is played in real time. For more examples see http://www.mee.tcd.ie/ ∼ sigmedia/ifc/flicker/shots/ Figure 2.1: Flicker effect on a sequence of the Irish movie Rory O’More (1911). Previous work [4], [15] consider that flicker can be modeled as a spatially varying gain and 4soffset function. In+1(x, y) = a(x, y) · In(x, y) + b(x, y) (2.1) This equation establishes the relationship between the intensit</context><context>roved in section 4.7.1. Sequences affected by flicker show low frequency spatial degradation. Therefore the functions of gain a(x, y) and offset b(x, y) should be low frequency. Previous work by [4], [15] employs a 2-dimensional polynomial basis. For example: a(x, y) = a0,0 + a1,0 x + ... + ai,j x i y j b(x, y) = b0,0 + b1,0 x + ... + bi,j x i y j The figure 2.2 shows an example of flicker following t</context><context>first method to measure the flicker strength is based on the fact that the strength of the flicker is directly linked to the intensity mean of the image. This method has been often used in literature [4, 15, 12, 11] to check the quality of the results of a flicker-removal process in a sequence since the mean intensity of a sequence without flicker is generally steady. If we note: f(u) = u + δ(u) δ(u) represents </context><context>10sof a same shot, we have: ⎧⎪ ⎨ max(In+1) = a · max(In) + b min(In+1) = a · min(In) + b ⎪⎩ E[In+1] = a · E[In] + b Parameters a and b can be easily retrieved from these equations. Roosmalen’s method [15]. The zeroth order parameters are found by comparing the moments (variance and mean) of the 2 images. � var[In+1(x, y)] a = ; b = E[In+1(x, y)] − a · E[In(x, y)] var[In(x, y)] This method corresponds </context><context>atching function f. All the previous methods consider only global flicker (zero order in x and y). But we know that the flicker may have some spatial fluctuations. To deal with this aspect, Roosmalen [15] split the image into small overlapping blocks. As the flicker is assumed to be spatially low frequency, it is possible to use his zeroth order estimator on these blocks. But the estimation of paramet</context></contexts></citation><citation id="29600"><authors>E Weisstein</authors><title>The world of mathematics. Available at http://mathworld.wolfram.com</title><raw>E. Weisstein. The world of mathematics. Available at http://mathworld.wolfram.com/.</raw><contexts><context>ectively symmetric results. See the appendix A for more informations. We processed on a sequence of 100 frames the both estimations. We found with the classical model that the correlation coefficient [16] is not 1 but rather √ â1 · â2 = 0.99. The bias observed is quite important since the gain of each estimation is under evaluated of about 0.01, which means that usually the frames will look darker of </context></contexts></citation><citation id="29601"><authors>X Yang,N Chong</authors><title>Enhanced approach to film flicker removal. Society of PhotoInstrumentation Engineers</title><year>2000</year><raw>X. Yang and N. Chong. Enhanced approach to film flicker removal. Society of PhotoInstrumentation Engineers, 2000.</raw><contexts><context> var[In+1(x, y)] a = ; b = E[In+1(x, y)] − a · E[In(x, y)] var[In(x, y)] This method corresponds to the least mean square solution of the problem. This method is a popular method. It has been used by [17, 12] and the company Snell&amp;Wilcox had for instance based their flicker removal on this algorithm. Roosmalen had also proposed some other improvements for the flicker removal (cf. sections 4.1.2 and 5.1.2)</context></contexts></citation></citations><fileInfo><url>http://www.mee.tcd.ie/~sigmedia/publications/publis/master_fpitie/fpitie_master_thesis.pdf</url><repID>rep1</repID><conversionTrace>PDFLib TET</conversionTrace><checkSums><checkSum><fileType>pdf</fileType><sha1>eb21f9a1de204cfc850ab4d5803df7b859183f9d</sha1></checkSum></checkSums></fileInfo></document>