<document id="10.1.1.1.1576"><title src="SVM HeaderParse 0.1">ROBUST EGO-MOTION ESTIMATION AND 3D MODEL REFINEMENT USING DEPTH BASED PARALLAX MODEL</title><abstract src="SVM HeaderParse 0.1">We present an iterative algorithm for robustly estimating the egomotion and refining and updating a coarse, noisy and partial depth map using a depth based parallax model and brightness derivatives extracted from an image pair. Given a coarse, noisy and partial depth map acquired by a range-finder or obtained from a Digital Elevation Map (DEM), we first estimate the ego-motion by combining a global ego-motion constraint and a local brightness constancy constraint. Using the estimated camera motion and the available depth map estimate, motion of the 3D points is compensated. We utilize the fact that the resulting surface parallax field is an epipolar field and knowing its direction from the previous motion estimates, estimate its magnitude and use it to refine the depth map estimate. Instead of assuming a smooth parallax field or locally smooth depth models, we locally model the parallax magnitude using the depth map, formulate the problem as a generalized eigen-value analysis and obtain better results. In addition, confidence measures for depth estimates are provided which can be used to remove regions with potentially incorrect (and outliers in) depth estimates for robustly estimating ego-motion in the next iteration. Results on both synthetic and real examples are presented. 1.</abstract><keywords></keywords><authors></authors><citations src="ParsCit 1.0"><citation id="29619"><authors>T S Huang,A N Netravali</authors><title>Motion and structure from feature correspondences: A review</title><venue>Proceedings of the IEEE</venue><venType>CONFERENCE</venType><year>1994</year><pages>252--268</pages><volume>82</volume><raw>T.S. Huang and A.N. Netravali, “Motion and structure from feature correspondences: A review,” Proceedings of the IEEE, vol. 82, pp. 252–268, 1994.</raw><contexts><context>mages to estimate the egomotion and the depth map of the scene. Several researches have worked on the problem of ego-motion estimation and depth recovery using intensity images. Feature based methods [1][2] use features or tokens to get depth information and motion. Flow based methods [3][4] assume that optical flow is available. Direct methods [5][6][7][8][9][10][11] do not require intermediate step</context><context>n section 2.2 (for the first global iteration we use the entire image region). Let Ti, Ωi denote the ego-motion estimate from the previous global iteration (for the first global iteration, we use T = [0, 0, 1] T , Ω = [0, 0, 0] T ). Within each global iteration, we refine the egomotion estimate by performing local iterations as follows. Let δT, δΩ be the incremental ego-motion update for a local iteration.</context></contexts></citation><citation id="29620"><authors>G S Young,R Chellappa</authors><title>3-D motion estimation using a sequence of noisy stereo images: Models, estimation, and uniqueness results</title><venue>IEEE Trans. on Pattern Analysis and Machine Intelligence</venue><venType>JOURNAL</venType><year>1990</year><pages>735--759</pages><volume>12</volume><raw>G.S. Young and R. Chellappa, “3-D motion estimation using a sequence of noisy stereo images: Models, estimation, and uniqueness results,” IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 12, pp. 735–759, 1990.</raw><contexts><context>es to estimate the egomotion and the depth map of the scene. Several researches have worked on the problem of ego-motion estimation and depth recovery using intensity images. Feature based methods [1][2] use features or tokens to get depth information and motion. Flow based methods [3][4] assume that optical flow is available. Direct methods [5][6][7][8][9][10][11] do not require intermediate steps s</context></contexts></citation><citation id="29621"><authors>H Liu,R Chellappa,A Rosenfeld</authors><title>A hierarchical approach for obtaining structure from two-frame optical flow</title><venue>Proceedings of Workshop on Motion and Video Computing</venue><venType>CONFERENCE</venType><year>2002</year><pages>214--219</pages><raw>H. Liu, R. Chellappa, and A. Rosenfeld, “A hierarchical approach for obtaining structure from two-frame optical flow,” Proceedings of Workshop on Motion and Video Computing, pp. 214–219, 2002.</raw><contexts><context>e worked on the problem of ego-motion estimation and depth recovery using intensity images. Feature based methods [1][2] use features or tokens to get depth information and motion. Flow based methods [3][4] assume that optical flow is available. Direct methods [5][6][7][8][9][10][11] do not require intermediate steps such as feature extraction or flow computation and work directly with spatial and te</context></contexts></citation><citation id="29622"><authors>G Adiv</authors><title>Determining 3-d motion and structure from optical flow generated by several moving objects</title><venue>IEEE Trans. on Pattern Analysis and Machine Intelligence</venue><venType>JOURNAL</venType><year>1985</year><pages>384--401</pages><volume>7</volume><raw>G. Adiv, “Determining 3-d motion and structure from optical flow generated by several moving objects,” IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 7, no. 4, pp. 384–401, July 1985.</raw><contexts><context>orked on the problem of ego-motion estimation and depth recovery using intensity images. Feature based methods [1][2] use features or tokens to get depth information and motion. Flow based methods [3][4] assume that optical flow is available. Direct methods [5][6][7][8][9][10][11] do not require intermediate steps such as feature extraction or flow computation and work directly with spatial and tempo</context></contexts></citation><citation id="29623"><authors>Y Aloimonos,C M Brown</authors><title>Direct processing of curvilinear sensor motion from a sequence of perspective images</title><venue>in CVWS84</venue><venType>CONFERENCE</venType><year>1984</year><pages>72--77</pages><raw>Y. Aloimonos and C.M. Brown, “Direct processing of curvilinear sensor motion from a sequence of perspective images,” in CVWS84, 1984, pp. 72–77.</raw><contexts><context>covery using intensity images. Feature based methods [1][2] use features or tokens to get depth information and motion. Flow based methods [3][4] assume that optical flow is available. Direct methods [5][6][7][8][9][10][11] do not require intermediate steps such as feature extraction or flow computation and work directly with spatial and temporal image gradients. Most of the previous approaches assum</context></contexts></citation><citation id="29624"><authors>B K P Horn,E Weldon</authors><title>Direct methods for recovering motion,” IJCV</title><year>1988</year><pages>51--76</pages><raw>B.K.P. Horn and E. Weldon, “Direct methods for recovering motion,” IJCV, pp. 51–76, 1988.</raw><contexts><context>ery using intensity images. Feature based methods [1][2] use features or tokens to get depth information and motion. Flow based methods [3][4] assume that optical flow is available. Direct methods [5][6][7][8][9][10][11] do not require intermediate steps such as feature extraction or flow computation and work directly with spatial and temporal image gradients. Most of the previous approaches assumes </context><context>ns have been reached. Assuming brightness constancy, we have I(r, t) = I(r−u, t−s1) where I(r, t) and I(r, t − 1) denote the key and offset frames respectively. Then the 2D image motion u is given by [6] u = AhT + BΩ (1) where B = � xy −(f + f x2 ) y f (f + y2 � , h = xy ) − −x f f 1 � −f 0 0 −f , A = Z � x and (T ,Ω) denote the translational and rotay tional velocities. For estimating ego-motion and</context></contexts></citation><citation id="29625"><authors>K J Hanna</authors><title>Direct multi-resolution estimation of egomotion and structure from motion</title><venue>in MOTION91</venue><venType>CONFERENCE</venType><year>1991</year><pages>156--162</pages><raw>K.J. Hanna, “Direct multi-resolution estimation of egomotion and structure from motion,” in MOTION91, 1991, pp. 156–162.</raw><contexts><context> using intensity images. Feature based methods [1][2] use features or tokens to get depth information and motion. Flow based methods [3][4] assume that optical flow is available. Direct methods [5][6][7][8][9][10][11] do not require intermediate steps such as feature extraction or flow computation and work directly with spatial and temporal image gradients. Most of the previous approaches assumes loc</context><context>orhood or is a parametric function [13] that imposes smooth flow. The smoothness constraint on depths can be applied by assuming a smooth depth model (constant or planar) over the neighborhood (as in [7][10]) and directly using (4) and (3) to estimate Z. However, these assumptions are violated at depth boundaries. Also, the effect of noise in available depth map estimate (from a range finder or from </context></contexts></citation><citation id="29626"><authors>S Negahdaripour,N Kolagani,B Y Hayashi</authors><title>Direct motion stereo for passive navigation</title><venue>in CVPR92</venue><venType>CONFERENCE</venType><year>1992</year><pages>425--431</pages><raw>S. Negahdaripour, N. Kolagani, and B.Y. Hayashi, “Direct motion stereo for passive navigation,” in CVPR92, 1992, pp. 425–431.</raw><contexts><context>ing intensity images. Feature based methods [1][2] use features or tokens to get depth information and motion. Flow based methods [3][4] assume that optical flow is available. Direct methods [5][6][7][8][9][10][11] do not require intermediate steps such as feature extraction or flow computation and work directly with spatial and temporal image gradients. Most of the previous approaches assumes locall</context></contexts></citation><citation id="29627"><authors>R Kumar,P Anandan,K J Hanna</authors><title>Direct recovery of shape from multiple views: a parallax based approach</title><venue>Proceedings of the 12th IAPR International Conference on Pattern Recognition</venue><venType>CONFERENCE</venType><year>1994</year><pages>685--688</pages><volume>1</volume><raw>R. Kumar, P. Anandan, and K.J. Hanna, “Direct recovery of shape from multiple views: a parallax based approach,” Proceedings of the 12th IAPR International Conference on Pattern Recognition, vol. 1, pp. 685–688, 1994.</raw><contexts><context> intensity images. Feature based methods [1][2] use features or tokens to get depth information and motion. Flow based methods [3][4] assume that optical flow is available. Direct methods [5][6][7][8][9][10][11] do not require intermediate steps such as feature extraction or flow computation and work directly with spatial and temporal image gradients. Most of the previous approaches assumes locally s</context><context>ta may require a nonsmooth local depth refinement. We show how to use the epipolar constraint and model the parallax field appropriately to deal with such cases. Parallax based approaches proposed in [9][11] assume a dominant planar region to be present in the image or the presence of a small planar region for motion estimation [12]. Our approach does not require any such assumptions. Also, many of t</context></contexts></citation><citation id="29628"><authors>J R Bergen,P Anandan,K J Hanna,R Hingorani</authors><title>Hierarchical model-based motion estimation</title><venue>Proceedings of Eurpoean Conference on Computer Vision</venue><venType>CONFERENCE</venType><year>1992</year><pages>237--252</pages><raw>J.R. Bergen, P. Anandan, K.J. Hanna, and R. Hingorani, “Hierarchical model-based motion estimation,” Proceedings of Eurpoean Conference on Computer Vision, pp. 237–252, 1992.</raw><contexts><context>tensity images. Feature based methods [1][2] use features or tokens to get depth information and motion. Flow based methods [3][4] assume that optical flow is available. Direct methods [5][6][7][8][9][10][11] do not require intermediate steps such as feature extraction or flow computation and work directly with spatial and temporal image gradients. Most of the previous approaches assumes locally smoot</context><context>ood or is a parametric function [13] that imposes smooth flow. The smoothness constraint on depths can be applied by assuming a smooth depth model (constant or planar) over the neighborhood (as in [7][10]) and directly using (4) and (3) to estimate Z. However, these assumptions are violated at depth boundaries. Also, the effect of noise in available depth map estimate (from a range finder or from the </context></contexts></citation><citation id="29629"><authors>M Irani,P Anandan,M Cohen</authors><title>Direct recovery of planar-parallax from multiple frames</title><venue>IEEE Transactions on Pattern Analysis and Machine Intelligence</venue><venType>JOURNAL</venType><year>2002</year><pages>1528--1534</pages><volume>24</volume><raw>M. Irani, P. Anandan, and M. Cohen, “Direct recovery of planar-parallax from multiple frames,” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 24, no. 11, pp. 1528–1534, 2002.</raw><contexts><context>ity images. Feature based methods [1][2] use features or tokens to get depth information and motion. Flow based methods [3][4] assume that optical flow is available. Direct methods [5][6][7][8][9][10][11] do not require intermediate steps such as feature extraction or flow computation and work directly with spatial and temporal image gradients. Most of the previous approaches assumes locally smooth de</context><context>may require a nonsmooth local depth refinement. We show how to use the epipolar constraint and model the parallax field appropriately to deal with such cases. Parallax based approaches proposed in [9][11] assume a dominant planar region to be present in the image or the presence of a small planar region for motion estimation [12]. Our approach does not require any such assumptions. Also, many of the p</context></contexts></citation><citation id="29630"><authors>A K Agrawal,R Chellappa</authors><title>3d model refinement using surface-parallax</title><year>2004</year><raw>A.K. Agrawal and R. Chellappa, “3d model refinement using surface-parallax,” to be published in ICASSP, 2004.</raw><contexts><context>iately to deal with such cases. Parallax based approaches proposed in [9][11] assume a dominant planar region to be present in the image or the presence of a small planar region for motion estimation [12]. Our approach does not require any such assumptions. Also, many of the previous methods use the information from the entire image for estimating ego-motion which may not be useful and can even contri</context></contexts></citation><citation id="29631"><authors>H Liu,R Chellappa,A Rosenfeld</authors><title>Accurate dense optical flow estimation and segementation using adaptive structure tensors and a parametric model</title><venue>IEEE Transactions on Image Processing</venue><venType>JOURNAL</venType><year>2003</year><pages>1170--1180</pages><volume>12</volume><raw>H. Liu, R. Chellappa, and A. Rosenfeld, “Accurate dense optical flow estimation and segementation using adaptive structure tensors and a parametric model,” IEEE Transactions on Image Processing, vol. 12, no. 10, pp. 1170–1180, 2003.</raw><contexts><context>s such as above, a smoothness constraint is generally applied. For example, in optical flow estimation, it is often assumed that the flow is constant within a neighborhood or is a parametric function [13] that imposes smooth flow. The smoothness constraint on depths can be applied by assuming a smooth depth model (constant or planar) over the neighborhood (as in [7][10]) and directly using (4) and (3)</context><context>dance with ∆I. λ1 &gt; 0, λ2 = 0 4. Intensity variation in all directions. No sufficient structure. λ1 &gt; 0, λ2 &gt; 0 Confidence measures based on eigen-values and/or condition number have been proposed in [13][14]. We use C = ( λ1−λ2 λ1+λ2 )2 as the confidence measure for depth estimation. Homogeneous regions (case 1) can be identified by using a threshold on the sum of eigen-values. Regions where local ed</context></contexts></citation><citation id="29632"><authors>H Liu,T H Hong,M Herman,R Chellappa</authors><title>A general motion model and spatio-temporal filters for computing optical flow</title><venue>IJCV</venue><venType>JOURNAL</venType><year>1997</year><pages>141--172</pages><volume>22</volume><raw>H. Liu, T.H. Hong, M. Herman, and R. Chellappa, “A general motion model and spatio-temporal filters for computing optical flow,” IJCV, vol. 22, pp. 141–172, 1997.</raw><contexts><context>e with ∆I. λ1 &gt; 0, λ2 = 0 4. Intensity variation in all directions. No sufficient structure. λ1 &gt; 0, λ2 &gt; 0 Confidence measures based on eigen-values and/or condition number have been proposed in [13][14]. We use C = ( λ1−λ2 λ1+λ2 )2 as the confidence measure for depth estimation. Homogeneous regions (case 1) can be identified by using a threshold on the sum of eigen-values. Regions where local edge s</context></contexts></citation></citations><fileInfo><url>http://www.cfar.umd.edu/~aagrawal/agrawal_icip.pdf</url><repID>rep1</repID><conversionTrace>PDFLib TET</conversionTrace><checkSums><checkSum><fileType>pdf</fileType><sha1>b7bc5709bf69086868f2340bce3b8a010d4724a2</sha1></checkSum></checkSums></fileInfo></document>