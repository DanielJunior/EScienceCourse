<document id="10.1.1.1.1568"><clusterid>1447</clusterid><title src="SVM HeaderParse 0.1">Learning Partially Observable Action Models</title><abstract src="user correction - Legacy Corrections">In this paper we present tractable algorithms for learning a logical model of actions&apos; effects and preconditions in deterministic partially observable domains. These algorithms update a representation of the set of possible action models after every observation and action execution. We show that when actions are known to have no conditional effects, then the set of possible action models can be represented compactly indefinitely. We also show that certain desirable properties hold for actions that have conditional effects, and that sometimes those can be learned efficiently as well. Our approach takes time and space that are polynomial in the number of domain features, and it is the first exact solution that is tractable for a wide class of problems. It does so by representing the set of possible action models using propositional logic, while avoiding general-purpose logical inference. Learning in partially observable domains is difficult and intractable in general, but our results show that it can be solved exactly in large domains in which one can assume some structure for actions&apos; effects and preconditions. These results are relevant for more general settings, such as learning HMMs, reinforcement learning, and learning in partially observable stochastic domains.</abstract><keywords></keywords><authors><author id="null"><name src="user correction - Legacy Corrections">Eyal Amir</name><order src="user correction - Legacy Corrections">1</order></author></authors><citations src="ParsCit 1.0"><citation id="29520"><clusterid>1448</clusterid><authors>Eyal Amir,Stuart Russell</authors><title>Logical filtering</title><venue>in Proc. Eighteenth International Joint Conference on Artificial Intelligence (IJCAI ’03</venue><venType>CONFERENCE</venType><year>2003</year><pages>75--82</pages><publisher>Morgan Kaufmann</publisher><raw>Eyal Amir and Stuart Russell, ‘Logical filtering’, in Proc. Eighteenth International Joint Conference on Artificial Intelligence (IJCAI ’03), pp. 75–82. Morgan Kaufmann, (2003).</raw><paperid>10.1.1.1.1568</paperid></citation><citation id="29521"><clusterid>1449</clusterid><authors>Scott Benson</authors><title>Inductive learning of reactive action models</title><venue>in Proceedings of the 12th International Conference on Machine Learning (ICML-94</venue><venType>CONFERENCE</venType><year>1995</year><raw>Scott Benson, ‘Inductive learning of reactive action models’, in Proceedings of the 12th International Conference on Machine Learning (ICML-94), (1995).</raw><paperid>10.1.1.1.1568</paperid></citation><citation id="29522"><clusterid>1450</clusterid><authors>Lonnie Chrisman</authors><title>Abstract probabilistic modeling of action</title><venue>in Proc. National Conference on Artificial Intelligence (AAAI ’92</venue><venType>CONFERENCE</venType><year>1992</year><publisher>AAAI Press</publisher><raw>Lonnie Chrisman, ‘Abstract probabilistic modeling of action’, in Proc. National Conference on Artificial Intelligence (AAAI ’92). AAAI Press, (1992).</raw><paperid>10.1.1.1.1568</paperid></citation><citation id="29523"><clusterid>1451</clusterid><authors>Richard Fikes,Peter Hart,Nils Nilsson</authors><title>Learning and executing generalized robot plans</title><venue>Artificial Intelligence</venue><venType>JOURNAL</venType><year>1972</year><pages>251--288</pages><volume>3</volume><raw>Richard Fikes, Peter Hart, and Nils Nilsson, ‘Learning and executing generalized robot plans’, Artificial Intelligence, 3, 251–288, (1972).</raw><paperid>10.1.1.1.1568</paperid></citation><citation id="29524"><clusterid>1452</clusterid><authors>Yolanda Gil</authors><title>Learning by experimentation: Incremental refinement of incomplete planning domains</title><venue>in Proceedings of the 11th International Conference on Machine Learning (ICML-94</venue><venType>CONFERENCE</venType><year>1994</year><pages>10--13</pages><raw>Yolanda Gil, ‘Learning by experimentation: Incremental refinement of incomplete planning domains’, in Proceedings of the 11th International Conference on Machine Learning (ICML-94), pp. 10–13, (1994).</raw><paperid>10.1.1.1.1568</paperid></citation><citation id="29525"><clusterid>1453</clusterid><authors>Brian</authors><title>Hlubocky and Eyal Amir, ‘Knowledge-gathering agents in adventure games</title><venue>in AAAI-04 Workshop on Challenges in Game AI</venue><venType>CONFERENCE</venType><year>2004</year><publisher>AAAI Press</publisher><raw>Brian Hlubocky and Eyal Amir, ‘Knowledge-gathering agents in adventure games’, in AAAI-04 Workshop on Challenges in Game AI. AAAI Press, (2004).</raw><paperid>10.1.1.1.1568</paperid></citation><citation id="29526"><clusterid>1454</clusterid><authors>Leslie Pack Kaelbling,Michael L Littman,Anthony R Cassandra</authors><title>Planning and acting in partially observable stochastic domains</title><venue>Artificial Intelligence</venue><venType>JOURNAL</venType><year>1998</year><pages>99--134</pages><volume>101</volume><raw>Leslie Pack Kaelbling, Michael L. Littman, and Anthony R. Cassandra, ‘Planning and acting in partially observable stochastic domains’, Artificial Intelligence, 101, 99–134, (1998).</raw><paperid>10.1.1.1.1568</paperid></citation><citation id="29527"><clusterid>1455</clusterid><authors>Leslie Pack Kaelbling,Michael L Littman,Andrew W Moore</authors><title>Reinforcement learning: a survey</title><venue>Journal of Artificial Intelligence Research</venue><venType>JOURNAL</venType><year>1996</year><volume>4</volume><raw>Leslie Pack Kaelbling, Michael L. Littman, and Andrew W. Moore, ‘Reinforcement learning: a survey’, Journal of Artificial Intelligence Research, 4, 237–285, (1996).</raw><paperid>10.1.1.1.1568</paperid></citation><citation id="29528"><clusterid>1456</clusterid><authors>Michael Kearns,Yishay Mansour,Andrew Y Ng</authors><title>Approximate planning in large pomdps via reusable trajectories</title><venue>in Proceedings of the 12th Conference on Neural Information Processing Systems (NIPS’99</venue><venType>CONFERENCE</venType><year>2000</year><pages>1001--1007</pages><publisher>MIT Press</publisher><raw>Michael Kearns, Yishay Mansour, and Andrew Y. Ng, ‘Approximate planning in large pomdps via reusable trajectories’, in Proceedings of the 12th Conference on Neural Information Processing Systems (NIPS’99), pp. 1001–1007. MIT Press, (2000).</raw><paperid>10.1.1.1.1568</paperid></citation><citation id="29529"><clusterid>1457</clusterid><authors>Fangzhen Lin,Ray Reiter</authors><title>How to Progress a Database</title><venue>Artificial Intelligence</venue><venType>JOURNAL</venType><year>1997</year><pages>131--167</pages><volume>92</volume><raw>Fangzhen Lin and Ray Reiter, ‘How to Progress a Database’, Artificial Intelligence, 92(1-2), 131–167, (1997).</raw><paperid>10.1.1.1.1568</paperid></citation><citation id="29530"><clusterid>1458</clusterid><authors>Michael L Littman</authors><title>Algorithms for sequential decision making</title><venType>TECHREPORT</venType><year>1996</year><tech>Ph.D. dissertation</tech><raw>Michael L. Littman, Algorithms for sequential decision making, Ph.D. dissertation, Department of Computer Science, Brown University, 1996. Technical report CS-96-09.</raw><paperid>10.1.1.1.1568</paperid></citation><citation id="29531"><clusterid>1459</clusterid><authors>R Andrew McCallum</authors><title>Instance-based utile distinctions for reinforcement learning with hidden state</title><venue>in Proceedings of the 12th International Conference on Machine Learning (ICML-95</venue><venType>CONFERENCE</venType><year>1995</year><publisher>Morgan Kaufmann</publisher><raw>R. Andrew McCallum, ‘Instance-based utile distinctions for reinforcement learning with hidden state’, in Proceedings of the 12th International Conference on Machine Learning (ICML-95). Morgan Kaufmann, (1995).</raw><paperid>10.1.1.1.1568</paperid></citation><citation id="29532"><clusterid>1460</clusterid><authors>Nicolas Meuleau,Leonid Peshkin,Kee-Eung Kim,Leslie Pack</authors><title>Kaelbling, ‘Learning finite-state controllers for partially observable environments</title><venue>in Proc. Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI ’99</venue><venType>CONFERENCE</venType><year>1999</year><publisher>Morgan Kaufmann</publisher><raw>Nicolas Meuleau, Leonid Peshkin, Kee-Eung Kim, and Leslie Pack Kaelbling, ‘Learning finite-state controllers for partially observable environments’, in Proc. Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI ’99). Morgan Kaufmann, (1999).</raw><paperid>10.1.1.1.1568</paperid></citation><citation id="29533"><clusterid>1461</clusterid><authors>Andrew Y Ng,Michael Jordan</authors><title>Pegasus: A policy search method for large mdps and pomdps</title><venue>in Proc. Sixteenth Conference on Uncertainty in Artificial Intelligence (UAI ’00</venue><venType>CONFERENCE</venType><year>2000</year><pages>406--415</pages><publisher>Morgan Kaufmann</publisher><raw>Andrew Y. Ng and Michael Jordan, ‘Pegasus: A policy search method for large mdps and pomdps’, in Proc. Sixteenth Conference on Uncertainty in Artificial Intelligence (UAI ’00), pp. 406–415. Morgan Kaufmann, (2000).</raw><paperid>10.1.1.1.1568</paperid></citation><citation id="29534"><clusterid>1462</clusterid><authors>Tim Oates,Paul R Cohen</authors><title>Searching for planning operators with context-dependent and probabilistic effects</title><venue>in Proc. National Conference on Artificial Intelligence (AAAI ’96</venue><venType>CONFERENCE</venType><year>1996</year><pages>863--868</pages><publisher>AAAI Press</publisher><raw>Tim Oates and Paul R. Cohen, ‘Searching for planning operators with context-dependent and probabilistic effects’, in Proc. National Conference on Artificial Intelligence (AAAI ’96), pp. 863–868. AAAI Press, (1996).</raw><paperid>10.1.1.1.1568</paperid></citation><citation id="29535"><clusterid>1463</clusterid><authors>Hanna M Pasula,Luke S Zettlemoyer,Leslie Pack</authors><title>Kaelbling, ‘Learning probabilistic relational planning rules</title><year>2004</year><publisher>AAAI Press</publisher><raw>Hanna M. Pasula, Luke S. Zettlemoyer, and Leslie Pack Kaelbling, ‘Learning probabilistic relational planning rules’. AAAI Press, (2004).</raw><paperid>10.1.1.1.1568</paperid></citation><citation id="29536"><clusterid>1069</clusterid><authors>L R Rabiner</authors><title>A tutorial on hidden Markov models and selected applications in speech recognition</title><venue>Proceedings of the IEEE</venue><venType>CONFERENCE</venType><year>1989</year><volume>77</volume><raw>L. R. Rabiner, ‘A tutorial on hidden Markov models and selected applications in speech recognition’, Proceedings of the IEEE, 77(2), 257–285, (February 1989).</raw><paperid>10.1.1.1.1568</paperid></citation><citation id="29537"><clusterid>1464</clusterid><authors>Matthew D Schmill,Tim Oates,Paul R Cohen</authors><title>Learning planning operators in real-world, partially observable environments</title><venue>in Proceedings of the 5th Int’l Conf. on AI Planning and Scheduling (AIPS’00</venue><venType>CONFERENCE</venType><year>2000</year><pages>246--253</pages><publisher>AAAI Press</publisher><raw>Matthew D. Schmill, Tim Oates, and Paul R. Cohen, ‘Learning planning operators in real-world, partially observable environments’, in Proceedings of the 5th Int’l Conf. on AI Planning and Scheduling (AIPS’00), pp. 246–253. AAAI Press, (2000).</raw><paperid>10.1.1.1.1568</paperid></citation><citation id="29538"><clusterid>1465</clusterid><authors>Xuemei Wang</authors><title>Learning by observation and practice: an incremental approach for planning operator acquisition</title><venue>in Proceedings of the 12th International Conference on Machine Learning (ICML-95</venue><venType>CONFERENCE</venType><year>1995</year><pages>549--557</pages><publisher>Morgan Kaufmann</publisher><raw>Xuemei Wang, ‘Learning by observation and practice: an incremental approach for planning operator acquisition’, in Proceedings of the 12th International Conference on Machine Learning (ICML-95), pp. 549–557. Morgan Kaufmann, (1995).</raw><paperid>10.1.1.1.1568</paperid></citation><citation id="29539"><clusterid>1466</clusterid><authors>Mary-Anne Winslett</authors><title>Updating Logical Databases</title><year>1990</year><publisher>University Press</publisher><pubAddress>Cambridge</pubAddress><raw>Mary-Anne Winslett, Updating Logical Databases, Cambridge University Press, 1990.</raw><paperid>10.1.1.1.1568</paperid></citation></citations><fileInfo><crawldate>Nov 19, 2007</crawldate><repID>rep1</repID><conversionTrace>PDFLib TET</conversionTrace><urls><url>http://www.cs.uiuc.edu/~eyal/papers/model-learning.0.35-cogrob04-final.pdf</url></urls></fileInfo></document>