<document id="10.1.1.1.1569"><title src="SVM HeaderParse 0.1">Reasoning about Time and Knowledge in Neural-Symbolic Learning Systems</title><abstract src="SVM HeaderParse 0.1">We show that temporal logic and combinations of temporal logics and modal logics of knowledge can be effectively represented in artificial neural networks. We present a Translation Algorithm from temporal rules to neural networks, and show that the networks compute a fixed-point semantics of the rules. We also apply the translation to the muddy children puzzle, which has been used as a testbed for distributed multi-agent systems. We provide a complete solution to the puzzle with the use of simple neural networks, capable of reasoning about time and of knowledge acquisition through inductive learning. 1</abstract><keywords></keywords><authors><author id="4366"><name src="SVM HeaderParse 0.1">Artur S. D’avila Garcez Δ</name><email src="SVM HeaderParse 0.1">UK (aag@soi.city.ac.uk</email><order>1</order></author><author id="4367"><name src="SVM HeaderParse 0.1">Luis C. Lamb Λ</name><email src="SVM HeaderParse 0.1">lamb@inf.ufrgs.br</email><order>2</order></author></authors><citations src="ParsCit 1.0"><citation id="29540"><authors>J M Zurada</authors><title>Knowledge-based neurocomputing</title><year>2000</year><publisher>The MIT Press</publisher><raw>Cloete, I., &amp; Zurada, J. M. (Eds.). (2000). Knowledge-based neurocomputing. The MIT Press.</raw><contexts><context>olldobler, 1993). Until recently, neural-symbolic systems were not able to fully represent, reason and learn expressive languages other than propositional and fragments of first-order logic (Cloete &amp; Zurada, 2000). However, in (d’Avila Garcez et al., 2002b; d’Avila Garcez et al., 2002c; d’Avila Garcez et al., 2003), a new approach to knowledge representation and reasoning in neural-symbolic systems based on n</context></contexts></citation><citation id="29541"><authors>d’Avila Garcez,A S,K Broda</authors><title>Symbolic knowledge extraction from trained neural networks: A sound approach</title><venue>Artificial Intelligence</venue><venType>JOURNAL</venType><year>2001</year><pages>155--207</pages><volume>125</volume><raw>d’Avila Garcez, A. S., Broda, K., &amp; Gabbay, D. M. (2001). Symbolic knowledge extraction from trained neural networks: A sound approach. Artificial Intelligence, 125, 155–207.</raw><contexts><context> addition, N can be trained with examples using, e.g., Backpropagation, and using P as background knowledge (Pazzani &amp; Kibler, 1992). The knowledge acquired by training can then be extracted (d’Avila Garcez et al., 2001), closing the learning cycle (as in (Towell &amp; Shavlik, 1994)). For each agent (child), a C-ILP network can be created. Each network can be seen as representing a (learnable) possible world containing</context></contexts></citation><citation id="29542"><authors>d’Avila Garcez,A S,K Broda</authors><title>Neural-symbolic learning systems: Foundations and applications</title><venue>Perspectives in Neural Computing</venue><venType>CONFERENCE</venType><year>2002</year><publisher>Springer-Verlag</publisher><raw>d’Avila Garcez, A. S., Broda, K., &amp; Gabbay, D. M. (2002a). Neural-symbolic learning systems: Foundations and applications. Perspectives in Neural Computing. Springer-Verlag.</raw><contexts><context>d of knowledge acquisition through inductive learning. 1 Introduction Hybrid neural-symbolic systems concern the use of problem-specific symbolic knowledge within the neurocomputing paradigm (d’Avila Garcez et al., 2002a). Typically, translation algorithms from a symbolic to a connectionist representation and vice-versa are employed to provide either (i) a neural implementation of a logic, (ii) a logical characteris</context><context>ural-symbolic systems were not able to fully represent, reason and learn expressive languages other than propositional and fragments of first-order logic (Cloete &amp; Zurada, 2000). However, in (d’Avila Garcez et al., 2002b; d’Avila Garcez et al., 2002c; d’Avila Garcez et al., 2003), a new approach to knowledge representation and reasoning in neural-symbolic systems based on neural networks ensembles has been introduce</context><context>h K1q1, the input neuron associated with K1¬p2, and the input neuron associated with K1¬p3 are all activated (true). The Connectionist Inductive Learning and Logic Programming (C-ILP) System (d’Avila Garcez et al., 2002a; d’Avila Garcez &amp; Zaverucha, 1999) makes use of the above kind of translation. C-ILP is a massively parallel computational model based on an artificial neural network that integrates inductive learn</context><context>his paper. By combining a number of simple C-ILP networks, we are able to model individual and common knowledge. Each network represents a possible world or an agent’s current set of beliefs (d’Avila Garcez et al., 2002b). If we allow a number of ensembles like the one of Figure 2 to be combined, we can represent the evolution in time of an agent’s set of beliefs. This is exactly what is required for a complete solu</context></contexts></citation><citation id="29543"><authors>d’Avila Garcez,A S,L C Lamb,K Broda</authors><title>Distributed knowledge representation in neural-symbolic learning systems: a case study. Accepted for</title><venue>Proceedings of 16th International FLAIRS Conference. St. Augustine</venue><venType>CONFERENCE</venType><year>2003</year><pubAddress>Florida</pubAddress><raw>d’Avila Garcez, A. S., Lamb, L. C., Broda, K., &amp; Gabbay, D. M. (2003). Distributed knowledge representation in neural-symbolic learning systems: a case study. Accepted for Proceedings of 16th International FLAIRS Conference. St. Augustine Florida.</raw><contexts><context>on and learn expressive languages other than propositional and fragments of first-order logic (Cloete &amp; Zurada, 2000). However, in (d’Avila Garcez et al., 2002b; d’Avila Garcez et al., 2002c; d’Avila Garcez et al., 2003), a new approach to knowledge representation and reasoning in neural-symbolic systems based on neural networks ensembles has been introduced. This new approach shows that modal logics can be effectiv</context></contexts></citation><citation id="29544"><authors>d’Avila Garcez,A S,L C Lamb</authors><title>A connectionist inductive learning system for modal logic programming</title><venType>TECHREPORT</venType><year>2002</year><pubAddress>Imperial College, London</pubAddress><tech>Technical Report 2002/6</tech><raw>d’Avila Garcez, A. S., Lamb, L. C., &amp; Gabbay, D. M. (2002b). A connectionist inductive learning system for modal logic programming (Technical Report 2002/6). Department of Computing, Imperial College, London.</raw><contexts><context>d of knowledge acquisition through inductive learning. 1 Introduction Hybrid neural-symbolic systems concern the use of problem-specific symbolic knowledge within the neurocomputing paradigm (d’Avila Garcez et al., 2002a). Typically, translation algorithms from a symbolic to a connectionist representation and vice-versa are employed to provide either (i) a neural implementation of a logic, (ii) a logical characteris</context><context>ural-symbolic systems were not able to fully represent, reason and learn expressive languages other than propositional and fragments of first-order logic (Cloete &amp; Zurada, 2000). However, in (d’Avila Garcez et al., 2002b; d’Avila Garcez et al., 2002c; d’Avila Garcez et al., 2003), a new approach to knowledge representation and reasoning in neural-symbolic systems based on neural networks ensembles has been introduce</context><context>h K1q1, the input neuron associated with K1¬p2, and the input neuron associated with K1¬p3 are all activated (true). The Connectionist Inductive Learning and Logic Programming (C-ILP) System (d’Avila Garcez et al., 2002a; d’Avila Garcez &amp; Zaverucha, 1999) makes use of the above kind of translation. C-ILP is a massively parallel computational model based on an artificial neural network that integrates inductive learn</context><context>his paper. By combining a number of simple C-ILP networks, we are able to model individual and common knowledge. Each network represents a possible world or an agent’s current set of beliefs (d’Avila Garcez et al., 2002b). If we allow a number of ensembles like the one of Figure 2 to be combined, we can represent the evolution in time of an agent’s set of beliefs. This is exactly what is required for a complete solu</context></contexts></citation><citation id="29545"><authors>d’Avila Garcez,A S,L C Lamb</authors><title>A connectionist inductive learning system for modal logic programming</title><venue>Proceedings of IEEE International Conference on Neural Information Processing ICONIP’02</venue><venType>CONFERENCE</venType><year>2002</year><pages>(pp.</pages><pubAddress>Singapore</pubAddress><raw>d’Avila Garcez, A. S., Lamb, L. C., &amp; Gabbay, D. M. (2002c). A connectionist inductive learning system for modal logic programming. Proceedings of IEEE International Conference on Neural Information Processing ICONIP’02 (pp. 1992–1997). Singapore.</raw><contexts><context>d of knowledge acquisition through inductive learning. 1 Introduction Hybrid neural-symbolic systems concern the use of problem-specific symbolic knowledge within the neurocomputing paradigm (d’Avila Garcez et al., 2002a). Typically, translation algorithms from a symbolic to a connectionist representation and vice-versa are employed to provide either (i) a neural implementation of a logic, (ii) a logical characteris</context><context>ural-symbolic systems were not able to fully represent, reason and learn expressive languages other than propositional and fragments of first-order logic (Cloete &amp; Zurada, 2000). However, in (d’Avila Garcez et al., 2002b; d’Avila Garcez et al., 2002c; d’Avila Garcez et al., 2003), a new approach to knowledge representation and reasoning in neural-symbolic systems based on neural networks ensembles has been introduce</context><context>h K1q1, the input neuron associated with K1¬p2, and the input neuron associated with K1¬p3 are all activated (true). The Connectionist Inductive Learning and Logic Programming (C-ILP) System (d’Avila Garcez et al., 2002a; d’Avila Garcez &amp; Zaverucha, 1999) makes use of the above kind of translation. C-ILP is a massively parallel computational model based on an artificial neural network that integrates inductive learn</context><context>his paper. By combining a number of simple C-ILP networks, we are able to model individual and common knowledge. Each network represents a possible world or an agent’s current set of beliefs (d’Avila Garcez et al., 2002b). If we allow a number of ensembles like the one of Figure 2 to be combined, we can represent the evolution in time of an agent’s set of beliefs. This is exactly what is required for a complete solu</context></contexts></citation><citation id="29546"><authors>d’Avila Garcez,A S</authors><title>The connectionist inductive learning and logic programming system</title><venue>Applied Intelligence Journal, Special Issue on Neural Networks and Structured Knowledge</venue><venType>JOURNAL</venType><year>1999</year><pages>59--77</pages><volume>11</volume><raw>d’Avila Garcez, A. S., &amp; Zaverucha, G. (1999). The connectionist inductive learning and logic programming system. Applied Intelligence Journal, Special Issue on Neural Networks and Structured Knowledge, 11, 59–77.</raw></citation><citation id="29547"><authors>R Fagin,J Halpern,Y Moses</authors><title>Reasoning about knowledge</title><year>1995</year><publisher>MIT Press</publisher><raw>Fagin, R., Halpern, J., Moses, Y., &amp; Vardi, M. (1995). Reasoning about knowledge. MIT Press.</raw><contexts><context>nowledge and time. We have validated the Connectionist Temporal Logic (CTL) proposed here by applying it to a distributed time and knowledge representation problem known as the muddy children puzzle (Fagin et al., 1995). CTL provides a combined (multi-modal) connectionist system of knowledge and time, which allows the modelling of evolving situations such as changing environments or possible worlds. Although a numb</context><context>ork. 2 Connectionist Reasoning about Time and Knowledge Temporal logic and its combination with other modalities such as knowledge and belief operators have been the subject of intense investigation (Fagin et al., 1995). In this section, we use the muddy children puzzle, a testbed for distributed knowledge representation formalisms, to exemplify how knowledge and time can be expressed in a connectionist setting. We</context></contexts></citation><citation id="29548"><authors>J Y Halpern,R van der Meyden</authors><title>Complete axiomatizations for reasoning about knowledge and time</title><venue>SIAM Journal on Computing</venue><venType>JOURNAL</venType><year>2003</year><raw>Halpern, J. Y., van der Meyden, R., &amp; Vardi, M. Y. (2003). Complete axiomatizations for reasoning about knowledge and time. SIAM Journal on Computing. to appear.</raw></citation><citation id="29549"><authors>J Y Halpern</authors><title>The complexity of reasoning about knowledge and time I: lower bounds</title><venue>Journal of Computer and System Sciences</venue><venType>JOURNAL</venType><year>1986</year><pages>195--237</pages><volume>38</volume><raw>Halpern, J. Y., &amp; Vardi, M. (1986). The complexity of reasoning about knowledge and time I: lower bounds. Journal of Computer and System Sciences, 38, 195–237.</raw></citation><citation id="29550"><authors>S Holldobler</authors><title>Automated inferencing and connectionist models</title><venue>Postdoctoral Thesis, Intellektik, Informatik, TH</venue><venType>CONFERENCE</venType><year>1993</year><pubAddress>Darmstadt</pubAddress><raw>Holldobler, S. (1993). Automated inferencing and connectionist models. Postdoctoral Thesis, Intellektik, Informatik, TH Darmstadt.</raw><contexts><context>implementation of a logic, (ii) a logical characterisation of a neural system, or (iii) a hybrid learning system that brings together features from connectionism and symbolic artificial intelligence (Holldobler, 1993). Until recently, neural-symbolic systems were not able to fully represent, reason and learn expressive languages other than propositional and fragments of first-order logic (Cloete &amp; Zurada, 2000). </context></contexts></citation><citation id="29551"><authors>S Holldobler</authors><title>Toward a new massively parallel computational model for logic programming</title><venue>Proceedings of the Workshop on Combining Symbolic and Connectionist Processing, ECAI 94</venue><venType>CONFERENCE</venType><year>1994</year><pages>68--77</pages><raw>Holldobler, S., &amp; Kalinke, Y. (1994). Toward a new massively parallel computational model for logic programming. Proceedings of the Workshop on Combining Symbolic and Connectionist Processing, ECAI 94 (pp. 68–77).</raw></citation><citation id="29552"><authors>S Holldobler,Y Kalinke</authors><title>Approximating the semantics of logic programs by recurrent neural networks</title><venue>Applied Intelligence Journal, Special Issue on Neural Networks and Structured Knowledge</venue><venType>JOURNAL</venType><year>1999</year><pages>45--58</pages><volume>11</volume><raw>Holldobler, S., Kalinke, Y., &amp; Storr, H. P. (1999). Approximating the semantics of logic programs by recurrent neural networks. Applied Intelligence Journal, Special Issue on Neural Networks and Structured Knowledge, 11, 45–58.</raw></citation><citation id="29553"><authors>M R A Huth</authors><title>Logic in computer science: Modelling and reasoning about systems</title><year>2000</year><publisher>Cambridge University Press</publisher><raw>Huth, M. R. A., &amp; Ryan, M. D. (2000). Logic in computer science: Modelling and reasoning about systems. Cambridge University Press.</raw></citation><citation id="29554"><authors>J W Lloyd</authors><title>Foundations of logic programming</title><year>1987</year><publisher>Springer-Verlag</publisher><raw>Lloyd, J. W. (1987). Foundations of logic programming. Springer-Verlag.</raw><contexts><context>ny logic program P into a single hidden layer neural network N such that N computes the least fixed point of P. This provides a massively parallel model for computing the stable model semantics of P (Lloyd, 1987). In addition, N can be trained with examples using, e.g., Backpropagation, and using P as background knowledge (Pazzani &amp; Kibler, 1992). The knowledge acquired by training can then be extracted (d’A</context></contexts></citation><citation id="29555"><authors>M Pazzani</authors><title>The utility of knowledge in inductive learning</title><venue>Machine Learning</venue><venType>CONFERENCE</venType><year>1992</year><pages>57--94</pages><volume>9</volume><raw>Pazzani, M., &amp; Kibler, D. (1992). The utility of knowledge in inductive learning. Machine Learning, 9, 57–94.</raw></citation><citation id="29556"><authors>A S Rao</authors><title>Decision procedures for BDI logics</title><venue>Journal of Logic and Computation</venue><venType>JOURNAL</venType><year>1998</year><pages>293--343</pages><volume>8</volume><raw>Rao, A. S., &amp; Georgeff, M. P. (1998). Decision procedures for BDI logics. Journal of Logic and Computation, 8, 293–343.</raw></citation><citation id="29557"><authors>G G Towell</authors><title>Knowledge-based artificial neural networks</title><venue>Artificial Intelligence</venue><venType>JOURNAL</venType><year>1994</year><pages>119--165</pages><volume>70</volume><raw>Towell, G. G., &amp; Shavlik, J. W. (1994). Knowledge-based artificial neural networks. Artificial Intelligence, 70, 119–165.</raw></citation><citation id="29558"><authors>L G Valiant</authors><title>A theory of the learnable</title><venue>Communications of the ACM</venue><venType>JOURNAL</venType><year>1984</year><pages>1134--1142</pages><volume>27</volume><raw>Valiant, L. G. (1984). A theory of the learnable. Communications of the ACM, 27, 1134–1142.</raw><contexts><context>gates. � 8 Note that ○ is not required to precede every rule antecedent. In the network, neurons are labelled as ○K1L1 or K1L1 to differentiate the two concepts. 2s4 Conclusions In his seminal paper (Valiant, 1984), Valiant argues for the need of rich logic-based knowledge representation mechanisms within learning systems. In this paper, we have addressed such a need, yet complying with important principles of</context></contexts></citation></citations><fileInfo><url>http://www.soi.city.ac.uk/~aag/papers/nips2003.pdf</url><repID>rep1</repID><conversionTrace>PDFLib TET</conversionTrace><checkSums><checkSum><fileType>pdf</fileType><sha1>30bad99a199d0f374dd0ab4e3407e37c1712afd4</sha1></checkSum></checkSums></fileInfo></document>