<document id="10.1.1.1.1607"><title src="SVM HeaderParse 0.1">Building Trust into OO Components using a Genetic Analogy</title><abstract src="SVM HeaderParse 0.1">Despite the growing interest for component-based systems, few works tackle the question of the trust we can bring into a component. This paper presents a method and a tool for building trustable OO components. It is particularly adapted to a design-by-contract approach, where the specification is systematically derived into executable assertions (invariant properties, pre/postconditions of methods). A component is seen as an organic set composed of a specification, a given implementation and its embedded test cases. We propose an adaptation of mutation analysis to the OO paradigm that checks the consistency between specification/implementation and tests. Faulty programs, called &amp;quot;mutants&amp;quot;, are generated by systematic fault injection in the implementation. The quality of tests is related to the mutation score, i.e. the proportion of faulty programs it detects. The main contribution of this is to show how a similar idea can be used in the same context to address the problem of effective tests optimization. To map the genetic analogy to the test optimization problem, we consider mutant programs to be detected as the initial preys population and test cases as the predators population. The test selection consists of mutating the “predator ” test cases and crossing them over in order to improve their ability to kill the prey population. The feasibility of components validation using such a “Darwinian ” model and its usefulness for test optimization are studied. 1.</abstract><keywords></keywords><authors><author id="4464"><name src="SVM HeaderParse 0.1">Benoit Baudry</name><address src="SVM HeaderParse 0.1">IRISA, Campus Universitaire de Beaulieu, 35042 Rennes Cedex, France</address><email src="SVM HeaderParse 0.1">Benoit.Baudry @irisa.fr</email><order>1</order></author><author id="4465"><name src="SVM HeaderParse 0.1">Vu Le Hanh</name><address src="SVM HeaderParse 0.1">IRISA, Campus Universitaire de Beaulieu, 35042 Rennes Cedex, France</address><email src="SVM HeaderParse 0.1">vlhanh @irisa.fr</email><order>2</order></author><author id="4466"><name src="SVM HeaderParse 0.1">Jean-marc Jézéquel</name><address src="SVM HeaderParse 0.1">IRISA, Campus Universitaire de Beaulieu, 35042 Rennes Cedex, France</address><email src="SVM HeaderParse 0.1">Jean-Marc.Jezequel @irisa.fr</email><order>3</order></author><author id="4467"><name src="SVM HeaderParse 0.1">Yves Le Traon</name><address src="SVM HeaderParse 0.1">IRISA, Campus Universitaire de Beaulieu, 35042 Rennes Cedex, France</address><email src="SVM HeaderParse 0.1">Yves.Le_Traon @irisa.fr</email><order>4</order></author></authors><citations src="ParsCit 1.0"><citation id="30145"><authors>Y Le Traon,D Deveaux,J-M Jézéquel</authors><title>Selftestable components: from pragmatic tests to a designfor-testability methodology</title><venue>In proc. of TOOLSEurope’99. TOOLS</venue><venType>CONFERENCE</venType><year>1999</year><pages>96--107</pages><pubAddress>Nancy (France</pubAddress><raw>Y. Le Traon, D. Deveaux and J-M. Jézéquel, “Selftestable components: from pragmatic tests to a designfor-testability methodology,” In proc. of TOOLSEurope’99. TOOLS, June 1999, Nancy (France) 96-107.</raw><contexts><context> this initial lack of interest, testing and trusting objectoriented systems is receiving much more attention (see http://www.trusted-components.org/ and[Binder99] for a detailed state of the art). In [1], we presented a pragmatic approach for linking design and testing of classes, seen as basic unit test components. Each component is enhanced by the ability to invoke its own tests: components are mad</context><context>ified functionality is added a new feature which enables it to test itself: the component is made self-testable. Selftestable components have the ability to launch their own unit tests as detailed in [1]. From a methodological point of view, we argue that the trust we have in a component depends on the consistency between the specification (refined in executable contracts), the implementation and the</context><context>o achieve a complete design-for-trust process, the notion of structural test dependencies has been developed for modeling the systematic use of self-testable components for structural system test. In [1], the design-for-testability main methodology is outlined. In this paper, we detailed the testing-for-trust method while [14,15] describe the automatic production, from UML design models, of an integr</context></contexts></citation><citation id="30146"><authors>William E Howden,Yudong Huang</authors><title>Software Trustability</title><venue>In proc. of the IEEE Symposium on Adaptive processes- Decision and Control, XVII</venue><venType>CONFERENCE</venType><year>1970</year><pages>5--1</pages><raw>William E. Howden and Yudong Huang, “Software Trustability”, In proc. of the IEEE Symposium on Adaptive processes- Decision and Control, XVII, 1970, 5.1-5.5.</raw><contexts><context>o a component the ability to embed its selftest is a good thing for its testability, estimating the quality of the embedded tests becomes crucial for the component trustability. Software trustability [2], as an abstract software property, is difficult to estimate directly, one can only approach it by analyzing concrete factors that influence this qualitative property. In this paper, we consider that </context></contexts></citation><citation id="30147"><authors>B Meyer</authors><title>Applying ``design by contract</title><venue>IEEE Computer</venue><venType>JOURNAL</venType><year>1992</year><pages>40--51</pages><raw>B. Meyer. Applying ``design by contract''. IEEE Computer, pages 40--51, oct 1992.</raw><contexts><context>given implementation and its embedded test cases. With such definition the trustability of a component will be based on the consistency between these three aspects. In a “design-by-contract” approach [3,4], the specification is systematically derived in executable contracts (class invariants, pre/post condition assertions for class methods). If contracts are complete enough, they should be violated whe</context></contexts></citation><citation id="30148"><authors>J-M Jézéquel,M Train,C Mingins</authors><title>DesignPatterns and Contracts</title><year>1999</year><pages>0--201</pages><publisher>Addison-Wesley</publisher><raw>J-M. Jézéquel, M. Train and C. Mingins. DesignPatterns and Contracts. Addison-Wesley, 0ctober 1999. ISBN 0-201-30959-9.</raw><contexts><context>given implementation and its embedded test cases. With such definition the trustability of a component will be based on the consistency between these three aspects. In a “design-by-contract” approach [3,4], the specification is systematically derived in executable contracts (class invariants, pre/post condition assertions for class methods). If contracts are complete enough, they should be violated whe</context></contexts></citation><citation id="30149"><authors>R DeMillo,R Lipton,F Sayward</authors><title>Hints on Test Data Selection : Help For The Practicing Programmer</title><venue>IEEE Computer</venue><venType>JOURNAL</venType><year>1978</year><pages>34--41</pages><volume>11</volume><raw>R. DeMillo, R. Lipton, and F. Sayward, “Hints on Test Data Selection : Help For The Practicing Programmer,” IEEE Computer, vol. 11, pp. 34-41, 1978.</raw><contexts><context>n this paper, we propose a testing-for-trust methodology that helps checking the consistency of the component three facets. The methodology is an original adaptation from mutation analysis principles [5]: the quality of the test cases is related to the proportion of faulty programs it detects. Faulty programs are generated by systematic fault injection in the original implementation. In our approach,</context><context>ng for OO domainsMutation testing is a testing technique which was first designed to create effective test data, with an important fault revealing power [6,7]. It has been originally proposed in 1978 [5], and consists of creating a set of faulty versions or mutants of a program with the ultimate goal of designing a test cases set that distinguishes the program from all its mutants. In practice, fault</context></contexts></citation><citation id="30150"><authors>J Offutt,J Pan,K</authors><title>Tewary and T. Zhang &amp;quot;An experimental evaluation of data flow and mutation testing,&amp;quot; Software Practice and Experience, v 26, n 2</title><year>1996</year><raw>J. Offutt, J. Pan, K. Tewary and T. Zhang &amp;quot;An experimental evaluation of data flow and mutation testing,&amp;quot; Software Practice and Experience, v 26, n 2, February 1996.</raw><contexts><context>pproach realistic and useful. 3. Mutation testing for OO domainsMutation testing is a testing technique which was first designed to create effective test data, with an important fault revealing power [6,7]. It has been originally proposed in 1978 [5], and consists of creating a set of faulty versions or mutants of a program with the ultimate goal of designing a test cases set that distinguishes the pro</context><context>ct after its creation. Suppress a clone or copy instruction. Insert a clone instruction for each reference affectation. The mutation operators AOR, LOR, ROR and NOR are traditional mutation operators [8, 9, 6], the other operators having been introduced in this paper for the object-oriented domain. The data perturbation operator VCP allows to disturb state of data and to obtain a sensitivity analysis of pr</context><context>mponents has been defined based on the quality of their associatedstests (itself based on fault injection). For measuring test quality, the presented approach differs from classical mutation analysis [6, 8] as follows: - a reduced set of mutation operators is needed, - oracle functions are integrated to the component, while classical mutation analysis uses differences between original program and mutant</context></contexts></citation><citation id="30151"><authors>J Voas et K Miller</authors><title>The Revealing Power of a Test Case</title><venue>Software Testing, Verification and Reliability</venue><venType>JOURNAL</venType><year>1992</year><pages>25--42</pages><volume>2</volume><raw>J. Voas et K. Miller, “The Revealing Power of a Test Case”, Software Testing, Verification and Reliability, vol. 2, pp. 25-42, 1992.</raw><contexts><context>pproach realistic and useful. 3. Mutation testing for OO domainsMutation testing is a testing technique which was first designed to create effective test data, with an important fault revealing power [6,7]. It has been originally proposed in 1978 [5], and consists of creating a set of faulty versions or mutants of a program with the ultimate goal of designing a test cases set that distinguishes the pro</context><context>tors having been introduced in this paper for the object-oriented domain. The data perturbation operator VCP allows to disturb state of data and to obtain a sensitivity analysis of program similar to [7]. Operator RFI introduces object aliasing and object reference faults, specific to object-oriented programming: - reference to an object is stuck-at &amp;quot;void&amp;quot;, - object duplication instructions (clone/co</context></contexts></citation><citation id="30152"><authors>R DeMillo et A Offutt</authors><title>Constraint-Based Automatic Test Data Generation</title><venue>IEEE Transactions On Computers</venue><venType>JOURNAL</venType><year>1991</year><pages>900--910</pages><volume>17</volume><raw>R. DeMillo et A. Offutt, “Constraint-Based Automatic Test Data Generation”, IEEE Transactions On Computers, vol. 17, pp. 900-910, 1991.</raw><contexts><context>ct after its creation. Suppress a clone or copy instruction. Insert a clone instruction for each reference affectation. The mutation operators AOR, LOR, ROR and NOR are traditional mutation operators [8, 9, 6], the other operators having been introduced in this paper for the object-oriented domain. The data perturbation operator VCP allows to disturb state of data and to obtain a sensitivity analysis of pr</context><context>mponents has been defined based on the quality of their associatedstests (itself based on fault injection). For measuring test quality, the presented approach differs from classical mutation analysis [6, 8] as follows: - a reduced set of mutation operators is needed, - oracle functions are integrated to the component, while classical mutation analysis uses differences between original program and mutant</context></contexts></citation><citation id="30153"><authors>A J Offutt</authors><title>Investigation of the software testing coupling effect</title><venue>ACM Transaction on Software Engineering Methodology</venue><venType>JOURNAL</venType><year>1992</year><pages>3--18</pages><volume>1</volume><raw>A. J. Offutt, “Investigation of the software testing coupling effect”, ACM Transaction on Software Engineering Methodology, vol. 1, pp. 3-18, 1992.</raw><contexts><context>ct after its creation. Suppress a clone or copy instruction. Insert a clone instruction for each reference affectation. The mutation operators AOR, LOR, ROR and NOR are traditional mutation operators [8, 9, 6], the other operators having been introduced in this paper for the object-oriented domain. The data perturbation operator VCP allows to disturb state of data and to obtain a sensitivity analysis of pr</context></contexts></citation><citation id="30154"><authors>D E Goldberg</authors><title>Genetic Algorithms</title><venue>in Search, Optimization and Machine Learning</venue><venType>CONFERENCE</venType><year>1989</year><publisher>Addison Wesley</publisher><raw>D. E. Goldberg, Genetic Algorithms in Search, Optimization and Machine Learning, Addison Wesley, 1989.</raw><contexts><context>nition of a fitness function. In our case, this difficulty does not exist: the mutation score is the function that estimates the effectiveness of a test case. a) Genetic algorithms Genetic algorithms [10] have been first developed by John Holland [11], whose goal was to rigorously explain natural systems and then design artificial systems based on natural mechanisms. So, genetic algorithms are optimiz</context></contexts></citation><citation id="30155"><authors>J H Holland</authors><title>Robust algorithms for adaptation set in general formal framework</title><venue>In proc. of the 5th International Symposium on Software Reliability Engineering (ISSRE’94</venue><venType>CONFERENCE</venType><year>1994</year><pages>143--151</pages><pubAddress>Monterey (California</pubAddress><raw>J. H. Holland, “Robust algorithms for adaptation set in general formal framework”, ”, In proc. of the 5th International Symposium on Software Reliability Engineering (ISSRE’94), October 1994, Monterey (California), 143-151.</raw><contexts><context> difficulty does not exist: the mutation score is the function that estimates the effectiveness of a test case. a) Genetic algorithms Genetic algorithms [10] have been first developed by John Holland [11], whose goal was to rigorously explain natural systems and then design artificial systems based on natural mechanisms. So, genetic algorithms are optimization algorithms based on natural genetics and </context></contexts></citation><citation id="30156"><authors>Robert V Binder</authors><title>Testing Object-Oriented Systems :Models</title><year>1999</year><pages>0--201</pages><raw>Robert V. Binder. Testing Object-Oriented Systems :Models, Patterns, and Tools., Addison-Wesley, October 1999. ISBN 0-201-80938-9.</raw><contexts><context> components. Binder details the existing analogy between hardware and OO software testing and suggests an OO testing approach close to the “builtin-test” and “design-for-testability” hardware notions [12]. In this paper, we go even further than Binder suggests, and detail how to create self-testable OO components, with an explicit analogy with the “builtin-self-test” hardware terminology. Moreover, an</context></contexts></citation><citation id="30157"><authors>K Beck,E Gamma</authors><title>Test-Infected: Programmers Love Writing Tests</title><venue>Java Report</venue><venType>JOURNAL</venType><pages>37--50</pages><volume>1998</volume><raw>K. Beck and E. Gamma, &amp;quot;Test-Infected: Programmers Love Writing Tests,&amp;quot; Java Report, July1998, 37-50.</raw><contexts><context>cle function. Besides, the test problem may be seen from a pragmatic point of view, and some simple-to-apply methodology can be found in the literature, which are based on an explicit test philosophy [13]. In this paper, the proposed methodology is based, on a first step, of pragmatic unit test generation and aims at bridging the existing gap between unit and system dynamic tests. In a second step, ad</context></contexts></citation><citation id="30158"><authors>T Jéron,J-M Jézéquel,Y Le Traon,P Morel</authors><title>Efficient Strategies for Integration and Regression Testing of OO Systems</title><venue>In proc. of the 10th International Symposium on Software Reliability Engineering (ISSRE’99</venue><venType>CONFERENCE</venType><year>1999</year><pages>260--269</pages><raw>T. Jéron, J-M. Jézéquel, Y. Le Traon, and P. Morel, “Efficient Strategies for Integration and Regression Testing of OO Systems”, In proc. of the 10th International Symposium on Software Reliability Engineering (ISSRE’99), November 1999, Boca raton (Florida), 260-269.</raw><contexts><context>e systematic use of self-testable components for structural system test. In [1], the design-for-testability main methodology is outlined. In this paper, we detailed the testing-for-trust method while [14,15] describe the automatic production, from UML design models, of an integration test plan that both minimizes the test effort and the test duration for an object-oriented system. Concerning advanced tes</context></contexts></citation><citation id="30159"><authors>Y Le Traon,T Jéron,J-M Jézéquel,P Morel</authors><title>Efficient OO Integration and Regression Testing</title><venue>IEEE Transactions on Reliability</venue><venType>JOURNAL</venType><year>2000</year><raw>Y. Le Traon, T. Jéron, J-M. Jézéquel and P. Morel, “Efficient OO Integration and Regression Testing”, to be published in IEEE Transactions on Reliability, March 2000.</raw><contexts><context>e systematic use of self-testable components for structural system test. In [1], the design-for-testability main methodology is outlined. In this paper, we detailed the testing-for-trust method while [14,15] describe the automatic production, from UML design models, of an integration test plan that both minimizes the test effort and the test duration for an object-oriented system. Concerning advanced tes</context></contexts></citation><citation id="30160"><authors>B F Jones,H-H Sthamer,D E</authors><title>Eyres, “Automatic structural testing using genetic algorithms</title><venue>Software Engineering Journal, September</venue><venType>JOURNAL</venType><pages>299--306</pages><volume>96</volume><raw>B. F. Jones, H.-H. Sthamer and D. E. Eyres, “Automatic structural testing using genetic algorithms”, Software Engineering Journal, September 96, 299-306.</raw><contexts><context>fort and the test duration for an object-oriented system. Concerning advanced test generation based on genetic algorithms, genetic algorithms have been recently studied for two different problems. In [16], genetic algorithms are used in a control-flow coverage-oriented way: test sets are improved to reach such a predefined test adequacy criterion. In [17], genetic algorithms are used to perform some k</context></contexts></citation><citation id="30161"><authors>S A Wadekar,S S Gokhale</authors><title>Exploring cost and reliability tradeoffs in architectural alternatives using a genetic algorithm</title><venue>Boca Raton (Florida</venue><venType>CONFERENCE</venType><year>1999</year><raw>S. A. Wadekar, S. S. Gokhale, Exploring cost and reliability tradeoffs in architectural alternatives using a genetic algorithm, In proc. of the 10th International Symposium on Software Reliability Engineering (ISSRE’99), November 1999, Boca Raton (Florida)</raw><contexts><context>ecently studied for two different problems. In [16], genetic algorithms are used in a control-flow coverage-oriented way: test sets are improved to reach such a predefined test adequacy criterion. In [17], genetic algorithms are used to perform some kind of reliability assessment. In this paper, the application of genetic algorithm is coherent with the application of mutation analysis for test qualifi</context></contexts></citation></citations><fileInfo><url>http://www.irisa.fr/triskell/publis/2000/Baudry00b.pdf</url><repID>rep1</repID><conversionTrace>PDFLib TET</conversionTrace><checkSums><checkSum><fileType>pdf</fileType><sha1>8b6d1bb47890a676793f4bd412d2383dc53e0b6e</sha1></checkSum></checkSums></fileInfo></document>